{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Toma de contacto con RNNs</h1>\n",
    "    <h2>Made with ❤️ by Emilio Pomares Porras (@emiliothehuman)</h2>\n",
    "    </center>\n",
    "<br><img src=\"http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg\">\n",
    "<br><br>Nada mejor que un ejercicio inútil para familiarizarse con las RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importemos todas las librerías necesarias\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.contrib.keras as keras\n",
    "L = keras.layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseteemos la sesión (importante cada vez que se cambia el grafo de tf o el modelo)\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos los datos de entrenamiento:\n",
    "#   X <- secuencia de 0 a 999\n",
    "#   Y <- X ^ 2\n",
    "\n",
    "X_train = np.array(range(0,1000))[0:1000]\n",
    "Y_train = X_train * 2\n",
    "X_train = X_train.reshape(1000, 1, 1)\n",
    "Y_train = Y_train.reshape(1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de neuronas en el interior de la celda RNN\n",
    "\n",
    "HiddenUnits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de épocas\n",
    "\n",
    "nEpochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos el modelo: una sola unidad RNN simple, que tratará de predecir un escalar de salida\n",
    "# a partir de un escalar de entrada y el estado anterior\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(L.SimpleRNN(HiddenUnits, input_shape=(1,1), return_sequences=False))\n",
    "model.add(L.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos una clase descendiente de Callback para almacenar una historia de losses\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "        def on_train_begin(self, logs={}):\n",
    "            self.losses = []\n",
    "            \n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            self.losses.append(logs.get('loss'))\n",
    "            \n",
    "l = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compilar el modelo...\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 29\n",
      "Trainable params: 29\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Echemos un vistazo al modelo\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1330292.9680 - acc: 1.0000e-03 - val_loss: 1330124.1161 - val_acc: 1.0000e-03\n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1329974.0150 - acc: 1.0000e-03 - val_loss: 1329804.3833 - val_acc: 1.0000e-03\n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1329381.1080 - acc: 1.0000e-03 - val_loss: 1329013.6267 - val_acc: 1.0000e-03\n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 0s 212us/step - loss: 1328867.0450 - acc: 1.0000e-03 - val_loss: 1328699.9590 - val_acc: 1.0000e-03\n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1328550.6200 - acc: 1.0000e-03 - val_loss: 1328382.0253 - val_acc: 1.0000e-03\n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1328229.3270 - acc: 1.0000e-03 - val_loss: 1328063.6481 - val_acc: 1.0000e-03\n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1327911.2060 - acc: 1.0000e-03 - val_loss: 1327743.8202 - val_acc: 1.0000e-03\n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1327593.4030 - acc: 1.0000e-03 - val_loss: 1327425.7405 - val_acc: 1.0000e-03\n",
      "Epoch 9/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1327275.9180 - acc: 1.0000e-03 - val_loss: 1327106.4652 - val_acc: 1.0000e-03\n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1326958.0410 - acc: 0.0000e+00 - val_loss: 1326789.9246 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1326641.0940 - acc: 0.0000e+00 - val_loss: 1326475.3510 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1326323.6475 - acc: 0.0000e+00 - val_loss: 1326156.1923 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1326006.2920 - acc: 0.0000e+00 - val_loss: 1325840.2876 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1325689.0280 - acc: 0.0000e+00 - val_loss: 1325520.8724 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1325224.5210 - acc: 0.0000e+00 - val_loss: 1324914.7056 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1324769.3700 - acc: 0.0000e+00 - val_loss: 1324601.3205 - val_acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1324455.3840 - acc: 0.0000e+00 - val_loss: 1324290.9501 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1324140.9820 - acc: 0.0000e+00 - val_loss: 1323972.4248 - val_acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1323823.6740 - acc: 0.0000e+00 - val_loss: 1323657.2602 - val_acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1323507.7580 - acc: 0.0000e+00 - val_loss: 1323341.7341 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1323192.0320 - acc: 0.0000e+00 - val_loss: 1323024.2578 - val_acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1322875.6670 - acc: 0.0000e+00 - val_loss: 1322710.7364 - val_acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1322560.1270 - acc: 0.0000e+00 - val_loss: 1322392.6047 - val_acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1322242.5820 - acc: 0.0000e+00 - val_loss: 1322076.4747 - val_acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1321925.3670 - acc: 0.0000e+00 - val_loss: 1321760.2150 - val_acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 0s 105us/step - loss: 1321608.3180 - acc: 0.0000e+00 - val_loss: 1321441.0287 - val_acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 1321293.6850 - acc: 0.0000e+00 - val_loss: 1321125.0849 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1320975.6490 - acc: 0.0000e+00 - val_loss: 1320812.1157 - val_acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 0s 99us/step - loss: 1320660.7190 - acc: 0.0000e+00 - val_loss: 1320493.7648 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1320344.6710 - acc: 0.0000e+00 - val_loss: 1320179.4575 - val_acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1320028.3160 - acc: 0.0000e+00 - val_loss: 1319861.7133 - val_acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1319713.6360 - acc: 0.0000e+00 - val_loss: 1319548.8933 - val_acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1319399.4340 - acc: 0.0000e+00 - val_loss: 1319232.4732 - val_acc: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1319083.8970 - acc: 0.0000e+00 - val_loss: 1318919.0595 - val_acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1318771.8350 - acc: 0.0000e+00 - val_loss: 1318605.2379 - val_acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1318455.6060 - acc: 0.0000e+00 - val_loss: 1318290.3929 - val_acc: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1318138.6900 - acc: 0.0000e+00 - val_loss: 1317975.1382 - val_acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1317821.7580 - acc: 0.0000e+00 - val_loss: 1317655.6428 - val_acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1317506.9880 - acc: 0.0000e+00 - val_loss: 1317334.7199 - val_acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1317187.5740 - acc: 0.0000e+00 - val_loss: 1317021.0753 - val_acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 1316873.6160 - acc: 0.0000e+00 - val_loss: 1316706.0377 - val_acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1316558.0110 - acc: 0.0000e+00 - val_loss: 1316391.3225 - val_acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1316244.6010 - acc: 0.0000e+00 - val_loss: 1316078.0499 - val_acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1315931.7220 - acc: 0.0000e+00 - val_loss: 1315766.8409 - val_acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1315618.5950 - acc: 0.0000e+00 - val_loss: 1315455.3456 - val_acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1315304.6140 - acc: 0.0000e+00 - val_loss: 1315137.1754 - val_acc: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1314989.9720 - acc: 0.0000e+00 - val_loss: 1314822.4527 - val_acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1314676.4550 - acc: 0.0000e+00 - val_loss: 1314512.1678 - val_acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1314363.0480 - acc: 0.0000e+00 - val_loss: 1314197.9464 - val_acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1314047.3900 - acc: 0.0000e+00 - val_loss: 1313880.5451 - val_acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1313731.7230 - acc: 0.0000e+00 - val_loss: 1313567.6270 - val_acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1313418.1335 - acc: 0.0000e+00 - val_loss: 1313251.7330 - val_acc: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1313104.2200 - acc: 0.0000e+00 - val_loss: 1312940.4910 - val_acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1312791.2010 - acc: 0.0000e+00 - val_loss: 1312626.8002 - val_acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1312478.8400 - acc: 0.0000e+00 - val_loss: 1312310.2855 - val_acc: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1312161.3060 - acc: 0.0000e+00 - val_loss: 1311997.2713 - val_acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1311846.6940 - acc: 0.0000e+00 - val_loss: 1311681.0646 - val_acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1311532.9000 - acc: 0.0000e+00 - val_loss: 1311367.1429 - val_acc: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1311220.0495 - acc: 0.0000e+00 - val_loss: 1311051.8288 - val_acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1310907.0670 - acc: 0.0000e+00 - val_loss: 1310740.1428 - val_acc: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1310594.3830 - acc: 0.0000e+00 - val_loss: 1310432.1936 - val_acc: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1310282.6960 - acc: 0.0000e+00 - val_loss: 1310116.2148 - val_acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1309968.9180 - acc: 0.0000e+00 - val_loss: 1309807.8574 - val_acc: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1309659.2810 - acc: 0.0000e+00 - val_loss: 1309493.4807 - val_acc: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1309345.3340 - acc: 0.0000e+00 - val_loss: 1309180.8704 - val_acc: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1309031.3950 - acc: 0.0000e+00 - val_loss: 1308865.6581 - val_acc: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1308717.9500 - acc: 0.0000e+00 - val_loss: 1308554.8261 - val_acc: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1308403.2580 - acc: 0.0000e+00 - val_loss: 1308236.3441 - val_acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1308088.1490 - acc: 0.0000e+00 - val_loss: 1307923.7085 - val_acc: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1307776.7220 - acc: 0.0000e+00 - val_loss: 1307611.1170 - val_acc: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1307463.5340 - acc: 0.0000e+00 - val_loss: 1307298.3124 - val_acc: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1307151.1240 - acc: 0.0000e+00 - val_loss: 1306983.3735 - val_acc: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1306838.3140 - acc: 0.0000e+00 - val_loss: 1306671.1408 - val_acc: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1306525.5000 - acc: 0.0000e+00 - val_loss: 1306361.1604 - val_acc: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1306215.5800 - acc: 0.0000e+00 - val_loss: 1306049.2686 - val_acc: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1305903.9580 - acc: 0.0000e+00 - val_loss: 1305739.3620 - val_acc: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1305592.2720 - acc: 0.0000e+00 - val_loss: 1305427.5816 - val_acc: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1305278.4230 - acc: 0.0000e+00 - val_loss: 1305114.6944 - val_acc: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1304966.5000 - acc: 0.0000e+00 - val_loss: 1304801.5963 - val_acc: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1304654.0130 - acc: 0.0000e+00 - val_loss: 1304488.5280 - val_acc: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1304343.0700 - acc: 0.0000e+00 - val_loss: 1304175.9602 - val_acc: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1304029.3120 - acc: 0.0000e+00 - val_loss: 1303866.8174 - val_acc: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1303717.4750 - acc: 0.0000e+00 - val_loss: 1303552.7635 - val_acc: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1303404.6840 - acc: 0.0000e+00 - val_loss: 1303238.8939 - val_acc: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1303092.0150 - acc: 0.0000e+00 - val_loss: 1302926.7634 - val_acc: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1302780.0900 - acc: 0.0000e+00 - val_loss: 1302615.4880 - val_acc: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1302466.8720 - acc: 0.0000e+00 - val_loss: 1302303.2322 - val_acc: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1302155.3550 - acc: 0.0000e+00 - val_loss: 1301989.1115 - val_acc: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1301843.4980 - acc: 0.0000e+00 - val_loss: 1301678.7480 - val_acc: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1301533.1830 - acc: 0.0000e+00 - val_loss: 1301369.7489 - val_acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1301221.3055 - acc: 0.0000e+00 - val_loss: 1301057.1513 - val_acc: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1300910.6940 - acc: 0.0000e+00 - val_loss: 1300746.3907 - val_acc: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1300597.4380 - acc: 0.0000e+00 - val_loss: 1300431.6527 - val_acc: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1300284.2785 - acc: 0.0000e+00 - val_loss: 1300121.8551 - val_acc: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1299974.4240 - acc: 0.0000e+00 - val_loss: 1299810.5244 - val_acc: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1299662.0300 - acc: 0.0000e+00 - val_loss: 1299500.1922 - val_acc: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1299352.7710 - acc: 0.0000e+00 - val_loss: 1299187.7573 - val_acc: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1299040.1840 - acc: 0.0000e+00 - val_loss: 1298878.9520 - val_acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1298732.3260 - acc: 0.0000e+00 - val_loss: 1298564.2248 - val_acc: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1298418.2770 - acc: 0.0000e+00 - val_loss: 1298255.7146 - val_acc: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1298107.1140 - acc: 0.0000e+00 - val_loss: 1297944.1940 - val_acc: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1297796.8400 - acc: 0.0000e+00 - val_loss: 1297632.6857 - val_acc: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1297485.3610 - acc: 0.0000e+00 - val_loss: 1297318.5255 - val_acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1297173.8065 - acc: 0.0000e+00 - val_loss: 1297012.0238 - val_acc: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1296866.2260 - acc: 0.0000e+00 - val_loss: 1296700.4048 - val_acc: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1296554.2580 - acc: 0.0000e+00 - val_loss: 1296390.8710 - val_acc: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1296242.6170 - acc: 0.0000e+00 - val_loss: 1296077.1893 - val_acc: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1295930.3560 - acc: 0.0000e+00 - val_loss: 1295767.4402 - val_acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1295618.7780 - acc: 0.0000e+00 - val_loss: 1295454.3918 - val_acc: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1295306.7980 - acc: 0.0000e+00 - val_loss: 1295143.0921 - val_acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1294995.5390 - acc: 0.0000e+00 - val_loss: 1294830.3612 - val_acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1294684.1740 - acc: 0.0000e+00 - val_loss: 1294520.5733 - val_acc: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1294372.6270 - acc: 0.0000e+00 - val_loss: 1294208.1826 - val_acc: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1294060.7180 - acc: 0.0000e+00 - val_loss: 1293900.9373 - val_acc: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1293750.1670 - acc: 0.0000e+00 - val_loss: 1293587.6860 - val_acc: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1293438.1180 - acc: 0.0000e+00 - val_loss: 1293274.9485 - val_acc: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1293127.7540 - acc: 0.0000e+00 - val_loss: 1292963.0945 - val_acc: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1292818.9420 - acc: 0.0000e+00 - val_loss: 1292653.5712 - val_acc: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1292509.6600 - acc: 0.0000e+00 - val_loss: 1292344.1332 - val_acc: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1292198.9640 - acc: 0.0000e+00 - val_loss: 1292035.7106 - val_acc: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1291888.7660 - acc: 0.0000e+00 - val_loss: 1291727.3062 - val_acc: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1291578.5935 - acc: 0.0000e+00 - val_loss: 1291413.9378 - val_acc: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1291268.6380 - acc: 0.0000e+00 - val_loss: 1291105.9142 - val_acc: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1290960.4640 - acc: 0.0000e+00 - val_loss: 1290795.5831 - val_acc: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1290647.6580 - acc: 0.0000e+00 - val_loss: 1290484.9456 - val_acc: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1290337.5960 - acc: 0.0000e+00 - val_loss: 1290177.7980 - val_acc: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1290028.7640 - acc: 0.0000e+00 - val_loss: 1289868.0406 - val_acc: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1289718.3720 - acc: 0.0000e+00 - val_loss: 1289554.7371 - val_acc: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1289405.7590 - acc: 0.0000e+00 - val_loss: 1289242.6544 - val_acc: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1289095.5710 - acc: 0.0000e+00 - val_loss: 1288932.5902 - val_acc: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1288783.8370 - acc: 0.0000e+00 - val_loss: 1288620.4252 - val_acc: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1288474.8660 - acc: 0.0000e+00 - val_loss: 1288309.6885 - val_acc: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1288163.7120 - acc: 0.0000e+00 - val_loss: 1288003.1282 - val_acc: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1287854.2100 - acc: 0.0000e+00 - val_loss: 1287688.6966 - val_acc: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1287542.5400 - acc: 0.0000e+00 - val_loss: 1287378.1504 - val_acc: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1287232.2240 - acc: 0.0000e+00 - val_loss: 1287070.5253 - val_acc: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1286923.4640 - acc: 0.0000e+00 - val_loss: 1286760.0264 - val_acc: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1286614.1390 - acc: 0.0000e+00 - val_loss: 1286450.1187 - val_acc: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1286303.8440 - acc: 0.0000e+00 - val_loss: 1286142.6078 - val_acc: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1285995.4300 - acc: 0.0000e+00 - val_loss: 1285834.4272 - val_acc: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1285687.5240 - acc: 0.0000e+00 - val_loss: 1285522.0626 - val_acc: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1285376.5190 - acc: 0.0000e+00 - val_loss: 1285213.2496 - val_acc: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1285066.9560 - acc: 0.0000e+00 - val_loss: 1284905.0204 - val_acc: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1284759.1580 - acc: 0.0000e+00 - val_loss: 1284594.1981 - val_acc: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1284449.2050 - acc: 0.0000e+00 - val_loss: 1284288.2381 - val_acc: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1284141.7590 - acc: 0.0000e+00 - val_loss: 1283976.2759 - val_acc: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1283829.4320 - acc: 0.0000e+00 - val_loss: 1283668.0148 - val_acc: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1283520.9100 - acc: 0.0000e+00 - val_loss: 1283359.2741 - val_acc: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1283213.8640 - acc: 0.0000e+00 - val_loss: 1283048.4678 - val_acc: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1282904.0880 - acc: 0.0000e+00 - val_loss: 1282741.5176 - val_acc: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1282595.2940 - acc: 0.0000e+00 - val_loss: 1282435.0975 - val_acc: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1282286.5560 - acc: 0.0000e+00 - val_loss: 1282121.5876 - val_acc: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1281976.4260 - acc: 0.0000e+00 - val_loss: 1281813.8656 - val_acc: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1281669.6420 - acc: 0.0000e+00 - val_loss: 1281507.8198 - val_acc: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1281362.6240 - acc: 0.0000e+00 - val_loss: 1281199.9281 - val_acc: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1281054.1150 - acc: 0.0000e+00 - val_loss: 1280891.1317 - val_acc: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1280745.8750 - acc: 0.0000e+00 - val_loss: 1280584.4700 - val_acc: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1280438.2360 - acc: 0.0000e+00 - val_loss: 1280273.9465 - val_acc: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1280128.4750 - acc: 0.0000e+00 - val_loss: 1279969.5462 - val_acc: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1279822.6260 - acc: 0.0000e+00 - val_loss: 1279660.5087 - val_acc: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1279513.8720 - acc: 0.0000e+00 - val_loss: 1279352.8609 - val_acc: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1279205.6260 - acc: 0.0000e+00 - val_loss: 1279044.6036 - val_acc: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1278896.2910 - acc: 0.0000e+00 - val_loss: 1278735.4880 - val_acc: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1278587.8800 - acc: 0.0000e+00 - val_loss: 1278426.8084 - val_acc: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1278280.9010 - acc: 0.0000e+00 - val_loss: 1278115.1257 - val_acc: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1277971.3080 - acc: 0.0000e+00 - val_loss: 1277812.2969 - val_acc: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1277666.1410 - acc: 0.0000e+00 - val_loss: 1277504.0788 - val_acc: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1277358.7830 - acc: 0.0000e+00 - val_loss: 1277196.5989 - val_acc: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1277051.7250 - acc: 0.0000e+00 - val_loss: 1276887.4979 - val_acc: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1276744.0770 - acc: 0.0000e+00 - val_loss: 1276578.8895 - val_acc: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1276434.2910 - acc: 0.0000e+00 - val_loss: 1276272.5492 - val_acc: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1276127.6980 - acc: 0.0000e+00 - val_loss: 1275966.6237 - val_acc: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1275821.9870 - acc: 0.0000e+00 - val_loss: 1275658.4414 - val_acc: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1275513.2310 - acc: 0.0000e+00 - val_loss: 1275348.1492 - val_acc: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1275206.2895 - acc: 0.0000e+00 - val_loss: 1275042.6874 - val_acc: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1274898.3280 - acc: 0.0000e+00 - val_loss: 1274739.1570 - val_acc: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1274592.8590 - acc: 0.0000e+00 - val_loss: 1274430.9331 - val_acc: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1274284.4880 - acc: 0.0000e+00 - val_loss: 1274124.1986 - val_acc: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1273975.6330 - acc: 0.0000e+00 - val_loss: 1273811.7477 - val_acc: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1273666.4240 - acc: 0.0000e+00 - val_loss: 1273507.9626 - val_acc: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1273360.4240 - acc: 0.0000e+00 - val_loss: 1273195.6908 - val_acc: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1273050.3715 - acc: 0.0000e+00 - val_loss: 1272890.5291 - val_acc: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1272745.2555 - acc: 0.0000e+00 - val_loss: 1272584.0622 - val_acc: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1272440.9005 - acc: 0.0000e+00 - val_loss: 1272279.4536 - val_acc: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1272135.5760 - acc: 0.0000e+00 - val_loss: 1271976.1103 - val_acc: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1271830.9060 - acc: 0.0000e+00 - val_loss: 1271666.2006 - val_acc: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1271522.0810 - acc: 0.0000e+00 - val_loss: 1271361.0709 - val_acc: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1271216.2405 - acc: 0.0000e+00 - val_loss: 1271053.4113 - val_acc: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1270909.2640 - acc: 0.0000e+00 - val_loss: 1270748.6393 - val_acc: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1270603.9360 - acc: 0.0000e+00 - val_loss: 1270440.3199 - val_acc: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1270297.1960 - acc: 0.0000e+00 - val_loss: 1270136.0841 - val_acc: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1269992.1470 - acc: 0.0000e+00 - val_loss: 1269833.3049 - val_acc: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1269687.0300 - acc: 0.0000e+00 - val_loss: 1269524.2474 - val_acc: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1269378.8350 - acc: 0.0000e+00 - val_loss: 1269217.5576 - val_acc: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1269072.7960 - acc: 0.0000e+00 - val_loss: 1268911.3681 - val_acc: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1268764.9130 - acc: 0.0000e+00 - val_loss: 1268606.0168 - val_acc: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1268460.9140 - acc: 0.0000e+00 - val_loss: 1268293.5729 - val_acc: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1268151.7320 - acc: 0.0000e+00 - val_loss: 1267989.4834 - val_acc: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1267844.8040 - acc: 0.0000e+00 - val_loss: 1267685.6081 - val_acc: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1267539.2140 - acc: 0.0000e+00 - val_loss: 1267379.0248 - val_acc: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1267233.0560 - acc: 0.0000e+00 - val_loss: 1267071.2747 - val_acc: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1266924.0355 - acc: 0.0000e+00 - val_loss: 1266759.7930 - val_acc: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1266615.4790 - acc: 0.0000e+00 - val_loss: 1266459.8627 - val_acc: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1266311.5260 - acc: 0.0000e+00 - val_loss: 1266150.9411 - val_acc: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1266004.8400 - acc: 0.0000e+00 - val_loss: 1265843.1070 - val_acc: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1265697.3560 - acc: 0.0000e+00 - val_loss: 1265534.4201 - val_acc: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1265390.2600 - acc: 0.0000e+00 - val_loss: 1265230.0144 - val_acc: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1265086.5120 - acc: 0.0000e+00 - val_loss: 1264926.8652 - val_acc: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1264782.2920 - acc: 0.0000e+00 - val_loss: 1264622.3813 - val_acc: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1264476.3510 - acc: 0.0000e+00 - val_loss: 1264315.7628 - val_acc: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1264171.4080 - acc: 0.0000e+00 - val_loss: 1264008.0734 - val_acc: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1263865.3515 - acc: 0.0000e+00 - val_loss: 1263704.8223 - val_acc: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1263560.4660 - acc: 0.0000e+00 - val_loss: 1263403.0979 - val_acc: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1263257.1025 - acc: 0.0000e+00 - val_loss: 1263093.6436 - val_acc: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "1000/1000 [==============================] - 0s 107us/step - loss: 1262951.0040 - acc: 0.0000e+00 - val_loss: 1262792.9880 - val_acc: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1262647.1150 - acc: 0.0000e+00 - val_loss: 1262484.3530 - val_acc: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1262339.9585 - acc: 0.0000e+00 - val_loss: 1262180.4297 - val_acc: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1262037.6780 - acc: 0.0000e+00 - val_loss: 1261875.9369 - val_acc: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1261730.7940 - acc: 0.0000e+00 - val_loss: 1261571.1397 - val_acc: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1261427.1790 - acc: 0.0000e+00 - val_loss: 1261264.1081 - val_acc: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1261120.8700 - acc: 0.0000e+00 - val_loss: 1260959.2302 - val_acc: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1260815.1610 - acc: 0.0000e+00 - val_loss: 1260650.8972 - val_acc: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1260509.5180 - acc: 0.0000e+00 - val_loss: 1260348.6330 - val_acc: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1260204.3370 - acc: 0.0000e+00 - val_loss: 1260045.6116 - val_acc: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1259903.5140 - acc: 0.0000e+00 - val_loss: 1259739.9943 - val_acc: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1259598.2220 - acc: 0.0000e+00 - val_loss: 1259438.1811 - val_acc: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1259294.1280 - acc: 0.0000e+00 - val_loss: 1259134.3201 - val_acc: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1258988.0210 - acc: 0.0000e+00 - val_loss: 1258827.4392 - val_acc: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1258683.7340 - acc: 0.0000e+00 - val_loss: 1258526.7052 - val_acc: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1258382.1400 - acc: 0.0000e+00 - val_loss: 1258223.0220 - val_acc: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 1258077.8360 - acc: 0.0000e+00 - val_loss: 1257916.0509 - val_acc: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1257772.7160 - acc: 0.0000e+00 - val_loss: 1257612.6172 - val_acc: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1257468.4180 - acc: 0.0000e+00 - val_loss: 1257307.6318 - val_acc: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1257163.7500 - acc: 0.0000e+00 - val_loss: 1257000.5501 - val_acc: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1256857.5650 - acc: 0.0000e+00 - val_loss: 1256696.1707 - val_acc: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1256550.4970 - acc: 0.0000e+00 - val_loss: 1256392.7148 - val_acc: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1256246.1700 - acc: 0.0000e+00 - val_loss: 1256086.7659 - val_acc: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1255940.7560 - acc: 0.0000e+00 - val_loss: 1255779.8946 - val_acc: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1255636.4340 - acc: 0.0000e+00 - val_loss: 1255475.7195 - val_acc: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1255331.0570 - acc: 0.0000e+00 - val_loss: 1255167.0770 - val_acc: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1255025.2880 - acc: 0.0000e+00 - val_loss: 1254865.7643 - val_acc: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1254722.6480 - acc: 0.0000e+00 - val_loss: 1254559.7685 - val_acc: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1254418.6890 - acc: 0.0000e+00 - val_loss: 1254259.9345 - val_acc: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1254115.7300 - acc: 0.0000e+00 - val_loss: 1253956.9109 - val_acc: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1253813.3280 - acc: 0.0000e+00 - val_loss: 1253650.4590 - val_acc: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1253507.5460 - acc: 0.0000e+00 - val_loss: 1253348.2262 - val_acc: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1253202.5320 - acc: 0.0000e+00 - val_loss: 1253043.1992 - val_acc: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1252898.8840 - acc: 0.0000e+00 - val_loss: 1252736.3528 - val_acc: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1252593.6430 - acc: 0.0000e+00 - val_loss: 1252432.5755 - val_acc: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1252288.1060 - acc: 0.0000e+00 - val_loss: 1252126.5631 - val_acc: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1251983.0720 - acc: 0.0000e+00 - val_loss: 1251824.3907 - val_acc: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1251680.1240 - acc: 0.0000e+00 - val_loss: 1251521.2941 - val_acc: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1251375.6670 - acc: 0.0000e+00 - val_loss: 1251216.3210 - val_acc: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1251072.2930 - acc: 0.0000e+00 - val_loss: 1250912.4010 - val_acc: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1250768.4410 - acc: 0.0000e+00 - val_loss: 1250607.2805 - val_acc: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1250464.2620 - acc: 0.0000e+00 - val_loss: 1250302.5441 - val_acc: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1250160.0950 - acc: 0.0000e+00 - val_loss: 1250000.3471 - val_acc: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1249857.7380 - acc: 0.0000e+00 - val_loss: 1249700.3102 - val_acc: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1249555.6010 - acc: 0.0000e+00 - val_loss: 1249392.6003 - val_acc: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1249252.2700 - acc: 0.0000e+00 - val_loss: 1249093.4644 - val_acc: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1248950.8490 - acc: 0.0000e+00 - val_loss: 1248790.2841 - val_acc: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1248647.6900 - acc: 0.0000e+00 - val_loss: 1248490.4525 - val_acc: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1248345.4400 - acc: 0.0000e+00 - val_loss: 1248184.8418 - val_acc: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1248042.0660 - acc: 0.0000e+00 - val_loss: 1247882.7622 - val_acc: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1247739.0860 - acc: 0.0000e+00 - val_loss: 1247578.4258 - val_acc: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1247436.0210 - acc: 0.0000e+00 - val_loss: 1247277.3847 - val_acc: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1247134.1720 - acc: 0.0000e+00 - val_loss: 1246974.7702 - val_acc: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1246832.3920 - acc: 0.0000e+00 - val_loss: 1246670.0668 - val_acc: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1246529.3900 - acc: 0.0000e+00 - val_loss: 1246369.9099 - val_acc: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1246227.5950 - acc: 0.0000e+00 - val_loss: 1246069.5846 - val_acc: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1245924.7130 - acc: 0.0000e+00 - val_loss: 1245765.4719 - val_acc: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1245621.9360 - acc: 0.0000e+00 - val_loss: 1245461.7298 - val_acc: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1245317.1220 - acc: 0.0000e+00 - val_loss: 1245159.6417 - val_acc: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1245015.7150 - acc: 0.0000e+00 - val_loss: 1244854.5908 - val_acc: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1244710.9000 - acc: 0.0000e+00 - val_loss: 1244552.8028 - val_acc: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1244407.8890 - acc: 0.0000e+00 - val_loss: 1244250.1898 - val_acc: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1244106.9850 - acc: 0.0000e+00 - val_loss: 1243948.0536 - val_acc: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1243803.9260 - acc: 0.0000e+00 - val_loss: 1243646.0148 - val_acc: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1243502.4680 - acc: 0.0000e+00 - val_loss: 1243343.7131 - val_acc: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1243199.3570 - acc: 0.0000e+00 - val_loss: 1243041.0485 - val_acc: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1242897.0680 - acc: 0.0000e+00 - val_loss: 1242736.0761 - val_acc: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1242595.1820 - acc: 0.0000e+00 - val_loss: 1242437.9540 - val_acc: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1242291.8280 - acc: 0.0000e+00 - val_loss: 1242136.3250 - val_acc: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1241990.5407 - acc: 0.0000e+00 - val_loss: 1241827.7845 - val_acc: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1241688.0765 - acc: 0.0000e+00 - val_loss: 1241530.0077 - val_acc: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1241387.8420 - acc: 0.0000e+00 - val_loss: 1241230.7088 - val_acc: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1241089.0350 - acc: 0.0000e+00 - val_loss: 1240929.7074 - val_acc: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1240787.1100 - acc: 0.0000e+00 - val_loss: 1240626.9754 - val_acc: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1240485.2890 - acc: 0.0000e+00 - val_loss: 1240326.6060 - val_acc: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1240185.5385 - acc: 0.0000e+00 - val_loss: 1240026.2716 - val_acc: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1239884.0200 - acc: 0.0000e+00 - val_loss: 1239727.6118 - val_acc: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1239583.3110 - acc: 0.0000e+00 - val_loss: 1239425.0690 - val_acc: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1239281.7250 - acc: 0.0000e+00 - val_loss: 1239118.1093 - val_acc: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1238977.6210 - acc: 0.0000e+00 - val_loss: 1238821.2479 - val_acc: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1238680.6570 - acc: 0.0000e+00 - val_loss: 1238522.0772 - val_acc: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1238380.2520 - acc: 0.0000e+00 - val_loss: 1238220.4395 - val_acc: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1238078.9390 - acc: 0.0000e+00 - val_loss: 1237920.6873 - val_acc: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1237777.2700 - acc: 0.0000e+00 - val_loss: 1237621.1877 - val_acc: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1237476.2965 - acc: 0.0000e+00 - val_loss: 1237315.7143 - val_acc: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1237174.5615 - acc: 0.0000e+00 - val_loss: 1237017.2504 - val_acc: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1236874.6680 - acc: 0.0000e+00 - val_loss: 1236718.3638 - val_acc: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1236575.0520 - acc: 0.0000e+00 - val_loss: 1236416.8497 - val_acc: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1236275.5680 - acc: 0.0000e+00 - val_loss: 1236116.4382 - val_acc: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1235973.4680 - acc: 0.0000e+00 - val_loss: 1235816.5830 - val_acc: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1235674.0950 - acc: 0.0000e+00 - val_loss: 1235515.0768 - val_acc: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1235374.2485 - acc: 0.0000e+00 - val_loss: 1235213.9525 - val_acc: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1235073.3455 - acc: 0.0000e+00 - val_loss: 1234914.4349 - val_acc: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1234773.2540 - acc: 0.0000e+00 - val_loss: 1234615.6989 - val_acc: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1234473.6440 - acc: 0.0000e+00 - val_loss: 1234316.2875 - val_acc: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1234172.7880 - acc: 0.0000e+00 - val_loss: 1234013.4404 - val_acc: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1233872.6120 - acc: 0.0000e+00 - val_loss: 1233711.7767 - val_acc: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1233571.0270 - acc: 0.0000e+00 - val_loss: 1233414.8396 - val_acc: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1233272.2190 - acc: 0.0000e+00 - val_loss: 1233115.1480 - val_acc: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1232973.4150 - acc: 0.0000e+00 - val_loss: 1232814.6736 - val_acc: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1232671.5000 - acc: 0.0000e+00 - val_loss: 1232515.2841 - val_acc: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1232372.2030 - acc: 0.0000e+00 - val_loss: 1232214.8399 - val_acc: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1232073.6430 - acc: 0.0000e+00 - val_loss: 1231913.5320 - val_acc: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 1231773.2320 - acc: 0.0000e+00 - val_loss: 1231615.6874 - val_acc: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1231475.1070 - acc: 0.0000e+00 - val_loss: 1231313.9687 - val_acc: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1231174.2610 - acc: 0.0000e+00 - val_loss: 1231016.5118 - val_acc: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1230874.5790 - acc: 0.0000e+00 - val_loss: 1230717.2461 - val_acc: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1230576.2570 - acc: 0.0000e+00 - val_loss: 1230417.7639 - val_acc: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1230275.2145 - acc: 0.0000e+00 - val_loss: 1230114.8951 - val_acc: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1229974.3860 - acc: 0.0000e+00 - val_loss: 1229817.5795 - val_acc: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1229674.5660 - acc: 0.0000e+00 - val_loss: 1229516.4348 - val_acc: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1229374.2390 - acc: 0.0000e+00 - val_loss: 1229216.6651 - val_acc: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1229075.4930 - acc: 0.0000e+00 - val_loss: 1228913.2805 - val_acc: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1228774.7805 - acc: 0.0000e+00 - val_loss: 1228615.9637 - val_acc: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1228477.8180 - acc: 0.0000e+00 - val_loss: 1228319.8734 - val_acc: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1228178.1780 - acc: 0.0000e+00 - val_loss: 1228019.1477 - val_acc: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1227877.0460 - acc: 0.0000e+00 - val_loss: 1227718.2714 - val_acc: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1227576.8300 - acc: 0.0000e+00 - val_loss: 1227416.5342 - val_acc: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1227276.5690 - acc: 0.0000e+00 - val_loss: 1227120.6016 - val_acc: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1226978.7605 - acc: 0.0000e+00 - val_loss: 1226821.0003 - val_acc: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1226680.4760 - acc: 0.0000e+00 - val_loss: 1226522.6093 - val_acc: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1226381.4865 - acc: 0.0000e+00 - val_loss: 1226228.4710 - val_acc: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1226086.3510 - acc: 0.0000e+00 - val_loss: 1225923.7348 - val_acc: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1225784.5415 - acc: 0.0000e+00 - val_loss: 1225626.4235 - val_acc: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1225486.8360 - acc: 0.0000e+00 - val_loss: 1225329.6028 - val_acc: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1225187.1850 - acc: 0.0000e+00 - val_loss: 1225028.2648 - val_acc: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1224886.2980 - acc: 0.0000e+00 - val_loss: 1224729.2580 - val_acc: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1224587.2300 - acc: 0.0000e+00 - val_loss: 1224427.5429 - val_acc: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1224285.6380 - acc: 0.0000e+00 - val_loss: 1224128.1630 - val_acc: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1223986.3055 - acc: 0.0000e+00 - val_loss: 1223826.0594 - val_acc: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1223688.3580 - acc: 0.0000e+00 - val_loss: 1223531.2220 - val_acc: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1223389.7720 - acc: 0.0000e+00 - val_loss: 1223231.9504 - val_acc: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1223090.4210 - acc: 0.0000e+00 - val_loss: 1222933.4143 - val_acc: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1222791.7230 - acc: 0.0000e+00 - val_loss: 1222630.8895 - val_acc: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1222491.4010 - acc: 0.0000e+00 - val_loss: 1222334.5370 - val_acc: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1222192.4110 - acc: 0.0000e+00 - val_loss: 1222035.7155 - val_acc: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1221894.6190 - acc: 0.0000e+00 - val_loss: 1221734.0683 - val_acc: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1221593.5300 - acc: 0.0000e+00 - val_loss: 1221436.6840 - val_acc: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1221292.1445 - acc: 0.0000e+00 - val_loss: 1221135.5964 - val_acc: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1220994.4250 - acc: 0.0000e+00 - val_loss: 1220837.4391 - val_acc: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1220697.1050 - acc: 0.0000e+00 - val_loss: 1220541.3910 - val_acc: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1220400.4210 - acc: 0.0000e+00 - val_loss: 1220242.1726 - val_acc: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1220102.1760 - acc: 0.0000e+00 - val_loss: 1219945.7689 - val_acc: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1219802.1160 - acc: 0.0000e+00 - val_loss: 1219646.4547 - val_acc: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1219503.4025 - acc: 0.0000e+00 - val_loss: 1219343.2549 - val_acc: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1219204.2680 - acc: 0.0000e+00 - val_loss: 1219045.3929 - val_acc: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1218904.0860 - acc: 0.0000e+00 - val_loss: 1218747.5790 - val_acc: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1218606.4100 - acc: 0.0000e+00 - val_loss: 1218448.9035 - val_acc: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1218307.3550 - acc: 0.0000e+00 - val_loss: 1218152.4051 - val_acc: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1218010.0640 - acc: 0.0000e+00 - val_loss: 1217852.6599 - val_acc: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1217713.1545 - acc: 0.0000e+00 - val_loss: 1217555.0606 - val_acc: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 1217415.3145 - acc: 0.0000e+00 - val_loss: 1217259.3407 - val_acc: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1217119.6040 - acc: 0.0000e+00 - val_loss: 1216961.8018 - val_acc: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1216819.7640 - acc: 0.0000e+00 - val_loss: 1216665.3139 - val_acc: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1216521.7120 - acc: 0.0000e+00 - val_loss: 1216364.4549 - val_acc: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1216223.2315 - acc: 0.0000e+00 - val_loss: 1216068.4073 - val_acc: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1215927.3890 - acc: 0.0000e+00 - val_loss: 1215767.4521 - val_acc: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1215628.8620 - acc: 0.0000e+00 - val_loss: 1215475.0565 - val_acc: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1215333.7830 - acc: 0.0000e+00 - val_loss: 1215175.0259 - val_acc: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1215035.8755 - acc: 0.0000e+00 - val_loss: 1214877.6356 - val_acc: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1214738.5380 - acc: 0.0000e+00 - val_loss: 1214582.5596 - val_acc: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1214443.4740 - acc: 0.0000e+00 - val_loss: 1214286.6677 - val_acc: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "1000/1000 [==============================] - 0s 121us/step - loss: 1214145.2135 - acc: 0.0000e+00 - val_loss: 1213988.2235 - val_acc: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1213848.8860 - acc: 0.0000e+00 - val_loss: 1213688.9923 - val_acc: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1213550.3370 - acc: 0.0000e+00 - val_loss: 1213392.9667 - val_acc: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1213253.1015 - acc: 0.0000e+00 - val_loss: 1213096.0906 - val_acc: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1212957.3950 - acc: 0.0000e+00 - val_loss: 1212800.8548 - val_acc: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1212660.5430 - acc: 0.0000e+00 - val_loss: 1212505.2156 - val_acc: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1212364.9150 - acc: 0.0000e+00 - val_loss: 1212206.6666 - val_acc: 1.0000e-03\n",
      "Epoch 384/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1212066.9520 - acc: 1.0000e-03 - val_loss: 1211912.2213 - val_acc: 1.0000e-03\n",
      "Epoch 385/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1211769.7150 - acc: 1.0000e-03 - val_loss: 1211611.7401 - val_acc: 1.0000e-03\n",
      "Epoch 386/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1211469.7940 - acc: 1.0000e-03 - val_loss: 1211313.3277 - val_acc: 1.0000e-03\n",
      "Epoch 387/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1211171.1820 - acc: 1.0000e-03 - val_loss: 1211012.6332 - val_acc: 1.0000e-03\n",
      "Epoch 388/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1210873.5265 - acc: 1.0000e-03 - val_loss: 1210715.4605 - val_acc: 1.0000e-03\n",
      "Epoch 389/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1210577.3220 - acc: 1.0000e-03 - val_loss: 1210420.3779 - val_acc: 1.0000e-03\n",
      "Epoch 390/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1210279.2480 - acc: 1.0000e-03 - val_loss: 1210124.4347 - val_acc: 1.0000e-03\n",
      "Epoch 391/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1209981.7310 - acc: 1.0000e-03 - val_loss: 1209827.4037 - val_acc: 1.0000e-03\n",
      "Epoch 392/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1209686.5895 - acc: 1.0000e-03 - val_loss: 1209529.7085 - val_acc: 1.0000e-03\n",
      "Epoch 393/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1209391.6975 - acc: 1.0000e-03 - val_loss: 1209236.2169 - val_acc: 1.0000e-03\n",
      "Epoch 394/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1209096.2620 - acc: 1.0000e-03 - val_loss: 1208940.7116 - val_acc: 1.0000e-03\n",
      "Epoch 395/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1208799.8845 - acc: 1.0000e-03 - val_loss: 1208643.1779 - val_acc: 1.0000e-03\n",
      "Epoch 396/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1208503.5640 - acc: 1.0000e-03 - val_loss: 1208349.8402 - val_acc: 1.0000e-03\n",
      "Epoch 397/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1208207.6560 - acc: 1.0000e-03 - val_loss: 1208048.5326 - val_acc: 1.0000e-03\n",
      "Epoch 398/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1207908.3200 - acc: 1.0000e-03 - val_loss: 1207752.7745 - val_acc: 1.0000e-03\n",
      "Epoch 399/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1207613.5340 - acc: 1.0000e-03 - val_loss: 1207457.4633 - val_acc: 1.0000e-03\n",
      "Epoch 400/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1207316.0880 - acc: 1.0000e-03 - val_loss: 1207163.8109 - val_acc: 1.0000e-03\n",
      "Epoch 401/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1207021.6390 - acc: 1.0000e-03 - val_loss: 1206865.0302 - val_acc: 1.0000e-03\n",
      "Epoch 402/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1206724.7740 - acc: 1.0000e-03 - val_loss: 1206568.2446 - val_acc: 1.0000e-03\n",
      "Epoch 403/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1206427.2730 - acc: 1.0000e-03 - val_loss: 1206270.8807 - val_acc: 1.0000e-03\n",
      "Epoch 404/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1206133.4200 - acc: 1.0000e-03 - val_loss: 1205975.6332 - val_acc: 1.0000e-03\n",
      "Epoch 405/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1205836.9520 - acc: 1.0000e-03 - val_loss: 1205679.9567 - val_acc: 1.0000e-03\n",
      "Epoch 406/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1205540.0390 - acc: 1.0000e-03 - val_loss: 1205384.8260 - val_acc: 1.0000e-03\n",
      "Epoch 407/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1205244.7575 - acc: 1.0000e-03 - val_loss: 1205090.8487 - val_acc: 1.0000e-03\n",
      "Epoch 408/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1204950.8600 - acc: 1.0000e-03 - val_loss: 1204795.1261 - val_acc: 1.0000e-03\n",
      "Epoch 409/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1204655.0565 - acc: 1.0000e-03 - val_loss: 1204499.1940 - val_acc: 1.0000e-03\n",
      "Epoch 410/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1204360.5780 - acc: 1.0000e-03 - val_loss: 1204203.2928 - val_acc: 1.0000e-03\n",
      "Epoch 411/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1204064.3620 - acc: 1.0000e-03 - val_loss: 1203907.8939 - val_acc: 1.0000e-03\n",
      "Epoch 412/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1203767.8390 - acc: 1.0000e-03 - val_loss: 1203612.5488 - val_acc: 1.0000e-03\n",
      "Epoch 413/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1203473.2800 - acc: 1.0000e-03 - val_loss: 1203316.1682 - val_acc: 1.0000e-03\n",
      "Epoch 414/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1203176.7220 - acc: 1.0000e-03 - val_loss: 1203022.2354 - val_acc: 1.0000e-03\n",
      "Epoch 415/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1202882.4660 - acc: 1.0000e-03 - val_loss: 1202725.9208 - val_acc: 1.0000e-03\n",
      "Epoch 416/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1202587.3480 - acc: 1.0000e-03 - val_loss: 1202431.3177 - val_acc: 1.0000e-03\n",
      "Epoch 417/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1202291.5180 - acc: 1.0000e-03 - val_loss: 1202139.1466 - val_acc: 1.0000e-03\n",
      "Epoch 418/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1201996.1730 - acc: 1.0000e-03 - val_loss: 1201839.3342 - val_acc: 1.0000e-03\n",
      "Epoch 419/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1201701.3855 - acc: 1.0000e-03 - val_loss: 1201545.2620 - val_acc: 1.0000e-03\n",
      "Epoch 420/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1201406.4100 - acc: 1.0000e-03 - val_loss: 1201252.8238 - val_acc: 1.0000e-03\n",
      "Epoch 421/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1201112.4950 - acc: 1.0000e-03 - val_loss: 1200955.1781 - val_acc: 1.0000e-03\n",
      "Epoch 422/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1200816.6880 - acc: 1.0000e-03 - val_loss: 1200663.5200 - val_acc: 1.0000e-03\n",
      "Epoch 423/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1200522.7810 - acc: 1.0000e-03 - val_loss: 1200367.3356 - val_acc: 1.0000e-03\n",
      "Epoch 424/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1200226.8580 - acc: 1.0000e-03 - val_loss: 1200074.4028 - val_acc: 1.0000e-03\n",
      "Epoch 425/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1199932.5710 - acc: 1.0000e-03 - val_loss: 1199776.1042 - val_acc: 1.0000e-03\n",
      "Epoch 426/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1199638.2180 - acc: 1.0000e-03 - val_loss: 1199479.7815 - val_acc: 1.0000e-03\n",
      "Epoch 427/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1199340.9030 - acc: 1.0000e-03 - val_loss: 1199186.7781 - val_acc: 1.0000e-03\n",
      "Epoch 428/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1199044.4280 - acc: 1.0000e-03 - val_loss: 1198890.1246 - val_acc: 1.0000e-03\n",
      "Epoch 429/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1198749.1360 - acc: 1.0000e-03 - val_loss: 1198592.5284 - val_acc: 1.0000e-03\n",
      "Epoch 430/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1198451.2000 - acc: 1.0000e-03 - val_loss: 1198295.5379 - val_acc: 1.0000e-03\n",
      "Epoch 431/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1198154.0150 - acc: 1.0000e-03 - val_loss: 1198002.4495 - val_acc: 1.0000e-03\n",
      "Epoch 432/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1197858.9250 - acc: 1.0000e-03 - val_loss: 1197701.9986 - val_acc: 1.0000e-03\n",
      "Epoch 433/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1197562.8940 - acc: 1.0000e-03 - val_loss: 1197407.5106 - val_acc: 1.0000e-03\n",
      "Epoch 434/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1197269.7605 - acc: 1.0000e-03 - val_loss: 1197115.9305 - val_acc: 1.0000e-03\n",
      "Epoch 435/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1196978.2520 - acc: 1.0000e-03 - val_loss: 1196822.1521 - val_acc: 1.0000e-03\n",
      "Epoch 436/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1196683.4760 - acc: 1.0000e-03 - val_loss: 1196530.0622 - val_acc: 1.0000e-03\n",
      "Epoch 437/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1196389.7020 - acc: 1.0000e-03 - val_loss: 1196234.9804 - val_acc: 1.0000e-03\n",
      "Epoch 438/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1196096.1585 - acc: 1.0000e-03 - val_loss: 1195935.7261 - val_acc: 1.0000e-03\n",
      "Epoch 439/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1195800.6520 - acc: 1.0000e-03 - val_loss: 1195645.1129 - val_acc: 1.0000e-03\n",
      "Epoch 440/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1195507.4370 - acc: 1.0000e-03 - val_loss: 1195353.3713 - val_acc: 1.0000e-03\n",
      "Epoch 441/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1195213.8360 - acc: 1.0000e-03 - val_loss: 1195059.3895 - val_acc: 1.0000e-03\n",
      "Epoch 442/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1194919.1110 - acc: 1.0000e-03 - val_loss: 1194764.2047 - val_acc: 1.0000e-03\n",
      "Epoch 443/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1194623.9560 - acc: 1.0000e-03 - val_loss: 1194468.7439 - val_acc: 1.0000e-03\n",
      "Epoch 444/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1194330.5925 - acc: 1.0000e-03 - val_loss: 1194174.7910 - val_acc: 1.0000e-03\n",
      "Epoch 445/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1194037.0600 - acc: 1.0000e-03 - val_loss: 1193881.9693 - val_acc: 1.0000e-03\n",
      "Epoch 446/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1193743.5750 - acc: 1.0000e-03 - val_loss: 1193586.4797 - val_acc: 1.0000e-03\n",
      "Epoch 447/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1193447.2160 - acc: 1.0000e-03 - val_loss: 1193294.6286 - val_acc: 1.0000e-03\n",
      "Epoch 448/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1193154.4310 - acc: 1.0000e-03 - val_loss: 1192998.7191 - val_acc: 1.0000e-03\n",
      "Epoch 449/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1192859.9290 - acc: 1.0000e-03 - val_loss: 1192704.9537 - val_acc: 1.0000e-03\n",
      "Epoch 450/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1192564.7425 - acc: 1.0000e-03 - val_loss: 1192407.1142 - val_acc: 1.0000e-03\n",
      "Epoch 451/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1192270.9660 - acc: 1.0000e-03 - val_loss: 1192115.0555 - val_acc: 1.0000e-03\n",
      "Epoch 452/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1191976.7400 - acc: 1.0000e-03 - val_loss: 1191823.0514 - val_acc: 1.0000e-03\n",
      "Epoch 453/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1191682.3560 - acc: 1.0000e-03 - val_loss: 1191528.5796 - val_acc: 1.0000e-03\n",
      "Epoch 454/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1191389.8570 - acc: 1.0000e-03 - val_loss: 1191236.3520 - val_acc: 1.0000e-03\n",
      "Epoch 455/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1191095.5365 - acc: 1.0000e-03 - val_loss: 1190940.9230 - val_acc: 1.0000e-03\n",
      "Epoch 456/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1190803.1860 - acc: 1.0000e-03 - val_loss: 1190648.5862 - val_acc: 1.0000e-03\n",
      "Epoch 457/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1190509.4745 - acc: 1.0000e-03 - val_loss: 1190354.9710 - val_acc: 1.0000e-03\n",
      "Epoch 458/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1190218.2490 - acc: 1.0000e-03 - val_loss: 1190064.5476 - val_acc: 1.0000e-03\n",
      "Epoch 459/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1189927.2160 - acc: 1.0000e-03 - val_loss: 1189772.8418 - val_acc: 1.0000e-03\n",
      "Epoch 460/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1189633.3560 - acc: 1.0000e-03 - val_loss: 1189475.7644 - val_acc: 1.0000e-03\n",
      "Epoch 461/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1189338.6840 - acc: 1.0000e-03 - val_loss: 1189184.3217 - val_acc: 1.0000e-03\n",
      "Epoch 462/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1189046.1480 - acc: 1.0000e-03 - val_loss: 1188891.2107 - val_acc: 1.0000e-03\n",
      "Epoch 463/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1188752.7400 - acc: 1.0000e-03 - val_loss: 1188598.8576 - val_acc: 1.0000e-03\n",
      "Epoch 464/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1188459.3460 - acc: 1.0000e-03 - val_loss: 1188306.4250 - val_acc: 1.0000e-03\n",
      "Epoch 465/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1188166.6270 - acc: 1.0000e-03 - val_loss: 1188012.7852 - val_acc: 1.0000e-03\n",
      "Epoch 466/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1187874.5470 - acc: 1.0000e-03 - val_loss: 1187719.3611 - val_acc: 1.0000e-03\n",
      "Epoch 467/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1187581.2980 - acc: 1.0000e-03 - val_loss: 1187426.4400 - val_acc: 1.0000e-03\n",
      "Epoch 468/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1187288.9720 - acc: 1.0000e-03 - val_loss: 1187133.8401 - val_acc: 1.0000e-03\n",
      "Epoch 469/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1186994.0780 - acc: 1.0000e-03 - val_loss: 1186842.1571 - val_acc: 1.0000e-03\n",
      "Epoch 470/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1186702.4875 - acc: 1.0000e-03 - val_loss: 1186546.4126 - val_acc: 1.0000e-03\n",
      "Epoch 471/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1186410.1565 - acc: 1.0000e-03 - val_loss: 1186259.8359 - val_acc: 1.0000e-03\n",
      "Epoch 472/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1186120.9365 - acc: 1.0000e-03 - val_loss: 1185966.5050 - val_acc: 1.0000e-03\n",
      "Epoch 473/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1185829.5700 - acc: 1.0000e-03 - val_loss: 1185676.3907 - val_acc: 1.0000e-03\n",
      "Epoch 474/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1185537.2940 - acc: 1.0000e-03 - val_loss: 1185381.5073 - val_acc: 1.0000e-03\n",
      "Epoch 475/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1185244.2880 - acc: 1.0000e-03 - val_loss: 1185088.3240 - val_acc: 1.0000e-03\n",
      "Epoch 476/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1184950.4440 - acc: 1.0000e-03 - val_loss: 1184796.0658 - val_acc: 1.0000e-03\n",
      "Epoch 477/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1184657.6330 - acc: 1.0000e-03 - val_loss: 1184498.0676 - val_acc: 1.0000e-03\n",
      "Epoch 478/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1184362.4580 - acc: 1.0000e-03 - val_loss: 1184211.1002 - val_acc: 1.0000e-03\n",
      "Epoch 479/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1184073.1770 - acc: 1.0000e-03 - val_loss: 1183916.9784 - val_acc: 1.0000e-03\n",
      "Epoch 480/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1183779.4980 - acc: 1.0000e-03 - val_loss: 1183626.8743 - val_acc: 1.0000e-03\n",
      "Epoch 481/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1183486.7060 - acc: 1.0000e-03 - val_loss: 1183332.2695 - val_acc: 1.0000e-03\n",
      "Epoch 482/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1183192.2380 - acc: 1.0000e-03 - val_loss: 1183037.2972 - val_acc: 1.0000e-03\n",
      "Epoch 483/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1182900.0780 - acc: 1.0000e-03 - val_loss: 1182744.7782 - val_acc: 1.0000e-03\n",
      "Epoch 484/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1182609.2400 - acc: 1.0000e-03 - val_loss: 1182455.8112 - val_acc: 1.0000e-03\n",
      "Epoch 485/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1182318.0840 - acc: 1.0000e-03 - val_loss: 1182164.2674 - val_acc: 1.0000e-03\n",
      "Epoch 486/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1182026.2020 - acc: 1.0000e-03 - val_loss: 1181873.8331 - val_acc: 1.0000e-03\n",
      "Epoch 487/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1181734.8290 - acc: 1.0000e-03 - val_loss: 1181579.6428 - val_acc: 1.0000e-03\n",
      "Epoch 488/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1181442.8940 - acc: 1.0000e-03 - val_loss: 1181284.5701 - val_acc: 1.0000e-03\n",
      "Epoch 489/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1181149.8910 - acc: 1.0000e-03 - val_loss: 1180997.4784 - val_acc: 1.0000e-03\n",
      "Epoch 490/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1180857.9660 - acc: 1.0000e-03 - val_loss: 1180708.0960 - val_acc: 1.0000e-03\n",
      "Epoch 491/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1180567.6640 - acc: 1.0000e-03 - val_loss: 1180410.5538 - val_acc: 1.0000e-03\n",
      "Epoch 492/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1180273.3570 - acc: 1.0000e-03 - val_loss: 1180120.6418 - val_acc: 1.0000e-03\n",
      "Epoch 493/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1179981.1700 - acc: 1.0000e-03 - val_loss: 1179826.2669 - val_acc: 1.0000e-03\n",
      "Epoch 494/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1179687.7160 - acc: 1.0000e-03 - val_loss: 1179534.4336 - val_acc: 1.0000e-03\n",
      "Epoch 495/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1179394.7380 - acc: 1.0000e-03 - val_loss: 1179240.4228 - val_acc: 1.0000e-03\n",
      "Epoch 496/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1179102.2695 - acc: 1.0000e-03 - val_loss: 1178947.5755 - val_acc: 1.0000e-03\n",
      "Epoch 497/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1178811.8000 - acc: 1.0000e-03 - val_loss: 1178656.5364 - val_acc: 1.0000e-03\n",
      "Epoch 498/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1178518.8300 - acc: 1.0000e-03 - val_loss: 1178370.0773 - val_acc: 1.0000e-03\n",
      "Epoch 499/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1178229.8820 - acc: 1.0000e-03 - val_loss: 1178073.7480 - val_acc: 1.0000e-03\n",
      "Epoch 500/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1177935.3570 - acc: 1.0000e-03 - val_loss: 1177782.0846 - val_acc: 1.0000e-03\n",
      "Epoch 501/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1177643.6620 - acc: 1.0000e-03 - val_loss: 1177490.3527 - val_acc: 1.0000e-03\n",
      "Epoch 502/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1177350.6900 - acc: 1.0000e-03 - val_loss: 1177196.1211 - val_acc: 1.0000e-03\n",
      "Epoch 503/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1177057.6930 - acc: 1.0000e-03 - val_loss: 1176903.4217 - val_acc: 1.0000e-03\n",
      "Epoch 504/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1176768.0260 - acc: 1.0000e-03 - val_loss: 1176616.3975 - val_acc: 1.0000e-03\n",
      "Epoch 505/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1176478.8330 - acc: 1.0000e-03 - val_loss: 1176326.1378 - val_acc: 1.0000e-03\n",
      "Epoch 506/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1176187.2360 - acc: 1.0000e-03 - val_loss: 1176035.0796 - val_acc: 1.0000e-03\n",
      "Epoch 507/1000\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 1175896.9660 - acc: 1.0000e-03 - val_loss: 1175743.9106 - val_acc: 1.0000e-03\n",
      "Epoch 508/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1175604.3245 - acc: 1.0000e-03 - val_loss: 1175453.0077 - val_acc: 1.0000e-03\n",
      "Epoch 509/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1175316.4100 - acc: 1.0000e-03 - val_loss: 1175162.7476 - val_acc: 1.0000e-03\n",
      "Epoch 510/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1175024.5000 - acc: 1.0000e-03 - val_loss: 1174872.1974 - val_acc: 1.0000e-03\n",
      "Epoch 511/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1174733.7070 - acc: 1.0000e-03 - val_loss: 1174580.4396 - val_acc: 1.0000e-03\n",
      "Epoch 512/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1174442.3510 - acc: 1.0000e-03 - val_loss: 1174289.0627 - val_acc: 1.0000e-03\n",
      "Epoch 513/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1174151.3340 - acc: 1.0000e-03 - val_loss: 1173999.7086 - val_acc: 1.0000e-03\n",
      "Epoch 514/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1173861.5130 - acc: 1.0000e-03 - val_loss: 1173709.9819 - val_acc: 1.0000e-03\n",
      "Epoch 515/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1173570.8860 - acc: 1.0000e-03 - val_loss: 1173419.8785 - val_acc: 1.0000e-03\n",
      "Epoch 516/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1173279.3270 - acc: 1.0000e-03 - val_loss: 1173126.5936 - val_acc: 1.0000e-03\n",
      "Epoch 517/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1172988.9820 - acc: 1.0000e-03 - val_loss: 1172837.8830 - val_acc: 1.0000e-03\n",
      "Epoch 518/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1172700.5670 - acc: 1.0000e-03 - val_loss: 1172543.6586 - val_acc: 1.0000e-03\n",
      "Epoch 519/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1172407.8060 - acc: 1.0000e-03 - val_loss: 1172256.9883 - val_acc: 1.0000e-03\n",
      "Epoch 520/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1172118.8550 - acc: 1.0000e-03 - val_loss: 1171964.6758 - val_acc: 1.0000e-03\n",
      "Epoch 521/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1171828.2640 - acc: 1.0000e-03 - val_loss: 1171674.3244 - val_acc: 1.0000e-03\n",
      "Epoch 522/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1171538.5810 - acc: 1.0000e-03 - val_loss: 1171384.9733 - val_acc: 1.0000e-03\n",
      "Epoch 523/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1171250.1000 - acc: 1.0000e-03 - val_loss: 1171097.2194 - val_acc: 1.0000e-03\n",
      "Epoch 524/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1170960.7460 - acc: 1.0000e-03 - val_loss: 1170806.8428 - val_acc: 1.0000e-03\n",
      "Epoch 525/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1170670.5960 - acc: 1.0000e-03 - val_loss: 1170516.7364 - val_acc: 1.0000e-03\n",
      "Epoch 526/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1170379.1770 - acc: 1.0000e-03 - val_loss: 1170228.2430 - val_acc: 1.0000e-03\n",
      "Epoch 527/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1170092.0070 - acc: 1.0000e-03 - val_loss: 1169937.5685 - val_acc: 1.0000e-03\n",
      "Epoch 528/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1169800.6360 - acc: 1.0000e-03 - val_loss: 1169649.1286 - val_acc: 1.0000e-03\n",
      "Epoch 529/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1169511.4070 - acc: 1.0000e-03 - val_loss: 1169360.3270 - val_acc: 1.0000e-03\n",
      "Epoch 530/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1169220.6150 - acc: 1.0000e-03 - val_loss: 1169070.8763 - val_acc: 1.0000e-03\n",
      "Epoch 531/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1168932.0110 - acc: 1.0000e-03 - val_loss: 1168778.1042 - val_acc: 1.0000e-03\n",
      "Epoch 532/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1168642.8530 - acc: 1.0000e-03 - val_loss: 1168487.9228 - val_acc: 1.0000e-03\n",
      "Epoch 533/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1168352.8560 - acc: 1.0000e-03 - val_loss: 1168200.8413 - val_acc: 1.0000e-03\n",
      "Epoch 534/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1168064.5580 - acc: 1.0000e-03 - val_loss: 1167913.4467 - val_acc: 1.0000e-03\n",
      "Epoch 535/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1167775.3800 - acc: 1.0000e-03 - val_loss: 1167620.6228 - val_acc: 1.0000e-03\n",
      "Epoch 536/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1167486.2895 - acc: 1.0000e-03 - val_loss: 1167331.1288 - val_acc: 1.0000e-03\n",
      "Epoch 537/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1167197.1480 - acc: 1.0000e-03 - val_loss: 1167044.4142 - val_acc: 1.0000e-03\n",
      "Epoch 538/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1166908.5520 - acc: 1.0000e-03 - val_loss: 1166754.0386 - val_acc: 1.0000e-03\n",
      "Epoch 539/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1166616.6830 - acc: 1.0000e-03 - val_loss: 1166460.7328 - val_acc: 1.0000e-03\n",
      "Epoch 540/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1166325.0430 - acc: 1.0000e-03 - val_loss: 1166177.1508 - val_acc: 1.0000e-03\n",
      "Epoch 541/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1166038.2105 - acc: 1.0000e-03 - val_loss: 1165884.7369 - val_acc: 1.0000e-03\n",
      "Epoch 542/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1165749.4220 - acc: 1.0000e-03 - val_loss: 1165598.7651 - val_acc: 1.0000e-03\n",
      "Epoch 543/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1165461.1290 - acc: 1.0000e-03 - val_loss: 1165308.6294 - val_acc: 1.0000e-03\n",
      "Epoch 544/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1165171.9805 - acc: 1.0000e-03 - val_loss: 1165020.0878 - val_acc: 1.0000e-03\n",
      "Epoch 545/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1164883.9740 - acc: 1.0000e-03 - val_loss: 1164732.9217 - val_acc: 1.0000e-03\n",
      "Epoch 546/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1164595.7040 - acc: 1.0000e-03 - val_loss: 1164444.2794 - val_acc: 1.0000e-03\n",
      "Epoch 547/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1164307.4870 - acc: 1.0000e-03 - val_loss: 1164153.6759 - val_acc: 1.0000e-03\n",
      "Epoch 548/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1164018.6650 - acc: 1.0000e-03 - val_loss: 1163868.0022 - val_acc: 1.0000e-03\n",
      "Epoch 549/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1163731.5840 - acc: 1.0000e-03 - val_loss: 1163577.4037 - val_acc: 1.0000e-03\n",
      "Epoch 550/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1163439.9470 - acc: 1.0000e-03 - val_loss: 1163292.7544 - val_acc: 1.0000e-03\n",
      "Epoch 551/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1163155.0755 - acc: 1.0000e-03 - val_loss: 1163002.0603 - val_acc: 1.0000e-03\n",
      "Epoch 552/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1162866.0380 - acc: 1.0000e-03 - val_loss: 1162715.0390 - val_acc: 1.0000e-03\n",
      "Epoch 553/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1162578.8940 - acc: 1.0000e-03 - val_loss: 1162424.0457 - val_acc: 1.0000e-03\n",
      "Epoch 554/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1162288.8900 - acc: 1.0000e-03 - val_loss: 1162137.3209 - val_acc: 1.0000e-03\n",
      "Epoch 555/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1162001.2980 - acc: 1.0000e-03 - val_loss: 1161849.2953 - val_acc: 1.0000e-03\n",
      "Epoch 556/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1161711.2670 - acc: 1.0000e-03 - val_loss: 1161560.2508 - val_acc: 1.0000e-03\n",
      "Epoch 557/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1161423.3170 - acc: 1.0000e-03 - val_loss: 1161270.2916 - val_acc: 1.0000e-03\n",
      "Epoch 558/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1161134.0470 - acc: 1.0000e-03 - val_loss: 1160982.4257 - val_acc: 1.0000e-03\n",
      "Epoch 559/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1160847.7530 - acc: 1.0000e-03 - val_loss: 1160694.3909 - val_acc: 1.0000e-03\n",
      "Epoch 560/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1160558.9200 - acc: 1.0000e-03 - val_loss: 1160407.5113 - val_acc: 1.0000e-03\n",
      "Epoch 561/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1160271.9060 - acc: 1.0000e-03 - val_loss: 1160119.3181 - val_acc: 1.0000e-03\n",
      "Epoch 562/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1159984.2580 - acc: 1.0000e-03 - val_loss: 1159830.5657 - val_acc: 1.0000e-03\n",
      "Epoch 563/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1159695.0780 - acc: 1.0000e-03 - val_loss: 1159543.1407 - val_acc: 1.0000e-03\n",
      "Epoch 564/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1159406.4820 - acc: 1.0000e-03 - val_loss: 1159253.5412 - val_acc: 1.0000e-03\n",
      "Epoch 565/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1159116.4660 - acc: 1.0000e-03 - val_loss: 1158965.7248 - val_acc: 1.0000e-03\n",
      "Epoch 566/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1158828.5530 - acc: 1.0000e-03 - val_loss: 1158677.2253 - val_acc: 1.0000e-03\n",
      "Epoch 567/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1158541.6825 - acc: 1.0000e-03 - val_loss: 1158391.7425 - val_acc: 1.0000e-03\n",
      "Epoch 568/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1158256.1200 - acc: 1.0000e-03 - val_loss: 1158102.3291 - val_acc: 1.0000e-03\n",
      "Epoch 569/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1157966.4680 - acc: 1.0000e-03 - val_loss: 1157816.0636 - val_acc: 1.0000e-03\n",
      "Epoch 570/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1157678.4240 - acc: 1.0000e-03 - val_loss: 1157526.3947 - val_acc: 1.0000e-03\n",
      "Epoch 571/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1157388.8640 - acc: 1.0000e-03 - val_loss: 1157237.0903 - val_acc: 1.0000e-03\n",
      "Epoch 572/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1157100.5320 - acc: 1.0000e-03 - val_loss: 1156949.9092 - val_acc: 1.0000e-03\n",
      "Epoch 573/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1156812.2010 - acc: 1.0000e-03 - val_loss: 1156661.1696 - val_acc: 1.0000e-03\n",
      "Epoch 574/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1156524.4020 - acc: 1.0000e-03 - val_loss: 1156372.0888 - val_acc: 1.0000e-03\n",
      "Epoch 575/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1156235.7500 - acc: 1.0000e-03 - val_loss: 1156083.6561 - val_acc: 1.0000e-03\n",
      "Epoch 576/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1155947.0960 - acc: 1.0000e-03 - val_loss: 1155797.5611 - val_acc: 1.0000e-03\n",
      "Epoch 577/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1155659.6740 - acc: 1.0000e-03 - val_loss: 1155507.7213 - val_acc: 1.0000e-03\n",
      "Epoch 578/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1155372.4530 - acc: 1.0000e-03 - val_loss: 1155221.8748 - val_acc: 1.0000e-03\n",
      "Epoch 579/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1155084.5555 - acc: 1.0000e-03 - val_loss: 1154931.7038 - val_acc: 1.0000e-03\n",
      "Epoch 580/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1154797.4810 - acc: 1.0000e-03 - val_loss: 1154646.8688 - val_acc: 1.0000e-03\n",
      "Epoch 581/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1154509.5020 - acc: 1.0000e-03 - val_loss: 1154355.7037 - val_acc: 1.0000e-03\n",
      "Epoch 582/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1154221.0500 - acc: 1.0000e-03 - val_loss: 1154070.0782 - val_acc: 1.0000e-03\n",
      "Epoch 583/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1153931.6430 - acc: 1.0000e-03 - val_loss: 1153780.0317 - val_acc: 1.0000e-03\n",
      "Epoch 584/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1153644.4525 - acc: 1.0000e-03 - val_loss: 1153488.7787 - val_acc: 1.0000e-03\n",
      "Epoch 585/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1153356.9750 - acc: 1.0000e-03 - val_loss: 1153205.4906 - val_acc: 1.0000e-03\n",
      "Epoch 586/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1153071.3340 - acc: 1.0000e-03 - val_loss: 1152920.5173 - val_acc: 1.0000e-03\n",
      "Epoch 587/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1152784.1450 - acc: 1.0000e-03 - val_loss: 1152634.2450 - val_acc: 1.0000e-03\n",
      "Epoch 588/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1152497.3470 - acc: 1.0000e-03 - val_loss: 1152347.8162 - val_acc: 1.0000e-03\n",
      "Epoch 589/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1152211.4660 - acc: 1.0000e-03 - val_loss: 1152061.1652 - val_acc: 1.0000e-03\n",
      "Epoch 590/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1151923.9530 - acc: 1.0000e-03 - val_loss: 1151772.1758 - val_acc: 1.0000e-03\n",
      "Epoch 591/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1151637.6010 - acc: 1.0000e-03 - val_loss: 1151486.3175 - val_acc: 1.0000e-03\n",
      "Epoch 592/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1151352.1960 - acc: 1.0000e-03 - val_loss: 1151198.7614 - val_acc: 1.0000e-03\n",
      "Epoch 593/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1151064.8285 - acc: 1.0000e-03 - val_loss: 1150913.1769 - val_acc: 1.0000e-03\n",
      "Epoch 594/1000\n",
      "1000/1000 [==============================] - 0s 122us/step - loss: 1150779.2270 - acc: 1.0000e-03 - val_loss: 1150626.8414 - val_acc: 1.0000e-03\n",
      "Epoch 595/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1150493.1270 - acc: 1.0000e-03 - val_loss: 1150342.9390 - val_acc: 1.0000e-03\n",
      "Epoch 596/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1150206.6280 - acc: 1.0000e-03 - val_loss: 1150056.6696 - val_acc: 1.0000e-03\n",
      "Epoch 597/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1149920.7140 - acc: 1.0000e-03 - val_loss: 1149767.0713 - val_acc: 1.0000e-03\n",
      "Epoch 598/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1149632.5390 - acc: 1.0000e-03 - val_loss: 1149478.6848 - val_acc: 1.0000e-03\n",
      "Epoch 599/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1149343.7055 - acc: 1.0000e-03 - val_loss: 1149194.3693 - val_acc: 1.0000e-03\n",
      "Epoch 600/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1149059.5855 - acc: 1.0000e-03 - val_loss: 1148908.1966 - val_acc: 1.0000e-03\n",
      "Epoch 601/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1148774.1900 - acc: 1.0000e-03 - val_loss: 1148621.7161 - val_acc: 1.0000e-03\n",
      "Epoch 602/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1148488.9330 - acc: 1.0000e-03 - val_loss: 1148336.8518 - val_acc: 1.0000e-03\n",
      "Epoch 603/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1148204.1870 - acc: 1.0000e-03 - val_loss: 1148053.3591 - val_acc: 1.0000e-03\n",
      "Epoch 604/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1147919.2550 - acc: 1.0000e-03 - val_loss: 1147769.8944 - val_acc: 1.0000e-03\n",
      "Epoch 605/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1147633.5780 - acc: 1.0000e-03 - val_loss: 1147479.5341 - val_acc: 1.0000e-03\n",
      "Epoch 606/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1147344.1890 - acc: 1.0000e-03 - val_loss: 1147193.0795 - val_acc: 1.0000e-03\n",
      "Epoch 607/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1147057.2630 - acc: 1.0000e-03 - val_loss: 1146905.7777 - val_acc: 1.0000e-03\n",
      "Epoch 608/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1146771.9210 - acc: 1.0000e-03 - val_loss: 1146623.3900 - val_acc: 1.0000e-03\n",
      "Epoch 609/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1146487.5880 - acc: 1.0000e-03 - val_loss: 1146339.2444 - val_acc: 1.0000e-03\n",
      "Epoch 610/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1146203.8420 - acc: 1.0000e-03 - val_loss: 1146054.3477 - val_acc: 1.0000e-03\n",
      "Epoch 611/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1145918.7300 - acc: 1.0000e-03 - val_loss: 1145769.6429 - val_acc: 1.0000e-03\n",
      "Epoch 612/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1145632.3720 - acc: 1.0000e-03 - val_loss: 1145480.7824 - val_acc: 1.0000e-03\n",
      "Epoch 613/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1145344.3460 - acc: 1.0000e-03 - val_loss: 1145193.5887 - val_acc: 1.0000e-03\n",
      "Epoch 614/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1145056.2710 - acc: 1.0000e-03 - val_loss: 1144905.0265 - val_acc: 1.0000e-03\n",
      "Epoch 615/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1144769.3730 - acc: 1.0000e-03 - val_loss: 1144616.9793 - val_acc: 1.0000e-03\n",
      "Epoch 616/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1144482.1060 - acc: 1.0000e-03 - val_loss: 1144329.3107 - val_acc: 1.0000e-03\n",
      "Epoch 617/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1144195.2140 - acc: 1.0000e-03 - val_loss: 1144044.9259 - val_acc: 1.0000e-03\n",
      "Epoch 618/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1143912.7800 - acc: 1.0000e-03 - val_loss: 1143762.6906 - val_acc: 1.0000e-03\n",
      "Epoch 619/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1143628.7640 - acc: 1.0000e-03 - val_loss: 1143477.4818 - val_acc: 1.0000e-03\n",
      "Epoch 620/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1143343.6440 - acc: 1.0000e-03 - val_loss: 1143193.0371 - val_acc: 1.0000e-03\n",
      "Epoch 621/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1143058.1980 - acc: 1.0000e-03 - val_loss: 1142909.2309 - val_acc: 1.0000e-03\n",
      "Epoch 622/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1142772.2910 - acc: 1.0000e-03 - val_loss: 1142620.8962 - val_acc: 1.0000e-03\n",
      "Epoch 623/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1142486.1350 - acc: 1.0000e-03 - val_loss: 1142336.3323 - val_acc: 1.0000e-03\n",
      "Epoch 624/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1142200.9740 - acc: 1.0000e-03 - val_loss: 1142052.6797 - val_acc: 1.0000e-03\n",
      "Epoch 625/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1141916.4970 - acc: 1.0000e-03 - val_loss: 1141767.8108 - val_acc: 1.0000e-03\n",
      "Epoch 626/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1141630.9620 - acc: 1.0000e-03 - val_loss: 1141477.8808 - val_acc: 1.0000e-03\n",
      "Epoch 627/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1141342.3560 - acc: 1.0000e-03 - val_loss: 1141192.7939 - val_acc: 1.0000e-03\n",
      "Epoch 628/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1141056.2420 - acc: 1.0000e-03 - val_loss: 1140906.3799 - val_acc: 1.0000e-03\n",
      "Epoch 629/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1140771.4315 - acc: 1.0000e-03 - val_loss: 1140620.7421 - val_acc: 1.0000e-03\n",
      "Epoch 630/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1140487.1630 - acc: 1.0000e-03 - val_loss: 1140336.0107 - val_acc: 1.0000e-03\n",
      "Epoch 631/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1140201.3630 - acc: 1.0000e-03 - val_loss: 1140053.4780 - val_acc: 1.0000e-03\n",
      "Epoch 632/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1139917.6760 - acc: 1.0000e-03 - val_loss: 1139766.6896 - val_acc: 1.0000e-03\n",
      "Epoch 633/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 1139631.4525 - acc: 1.0000e-03 - val_loss: 1139479.8569 - val_acc: 1.0000e-03\n",
      "Epoch 634/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1139346.4880 - acc: 1.0000e-03 - val_loss: 1139195.2032 - val_acc: 1.0000e-03\n",
      "Epoch 635/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1139061.8400 - acc: 1.0000e-03 - val_loss: 1138912.1336 - val_acc: 1.0000e-03\n",
      "Epoch 636/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 1138777.4860 - acc: 1.0000e-03 - val_loss: 1138630.1675 - val_acc: 1.0000e-03\n",
      "Epoch 637/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1138493.8580 - acc: 1.0000e-03 - val_loss: 1138343.8183 - val_acc: 1.0000e-03\n",
      "Epoch 638/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1138208.8000 - acc: 1.0000e-03 - val_loss: 1138058.8779 - val_acc: 1.0000e-03\n",
      "Epoch 639/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1137924.7380 - acc: 1.0000e-03 - val_loss: 1137775.5217 - val_acc: 1.0000e-03\n",
      "Epoch 640/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1137640.3380 - acc: 1.0000e-03 - val_loss: 1137492.4526 - val_acc: 1.0000e-03\n",
      "Epoch 641/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1137356.0310 - acc: 1.0000e-03 - val_loss: 1137209.1423 - val_acc: 1.0000e-03\n",
      "Epoch 642/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1137074.4860 - acc: 1.0000e-03 - val_loss: 1136921.3205 - val_acc: 1.0000e-03\n",
      "Epoch 643/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1136789.4487 - acc: 1.0000e-03 - val_loss: 1136636.8096 - val_acc: 1.0000e-03\n",
      "Epoch 644/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1136505.7880 - acc: 1.0000e-03 - val_loss: 1136357.8996 - val_acc: 1.0000e-03\n",
      "Epoch 645/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1136222.8835 - acc: 1.0000e-03 - val_loss: 1136072.6428 - val_acc: 1.0000e-03\n",
      "Epoch 646/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1135938.8557 - acc: 1.0000e-03 - val_loss: 1135789.5490 - val_acc: 1.0000e-03\n",
      "Epoch 647/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1135658.0905 - acc: 1.0000e-03 - val_loss: 1135507.8950 - val_acc: 1.0000e-03\n",
      "Epoch 648/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1135375.1875 - acc: 1.0000e-03 - val_loss: 1135225.2333 - val_acc: 1.0000e-03\n",
      "Epoch 649/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1135092.5870 - acc: 1.0000e-03 - val_loss: 1134942.6813 - val_acc: 1.0000e-03\n",
      "Epoch 650/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1134807.8490 - acc: 1.0000e-03 - val_loss: 1134658.2930 - val_acc: 1.0000e-03\n",
      "Epoch 651/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1134523.6570 - acc: 1.0000e-03 - val_loss: 1134373.7380 - val_acc: 1.0000e-03\n",
      "Epoch 652/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1134241.0530 - acc: 1.0000e-03 - val_loss: 1134091.2483 - val_acc: 1.0000e-03\n",
      "Epoch 653/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1133959.4610 - acc: 1.0000e-03 - val_loss: 1133805.2252 - val_acc: 1.0000e-03\n",
      "Epoch 654/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1133673.5140 - acc: 1.0000e-03 - val_loss: 1133527.0147 - val_acc: 1.0000e-03\n",
      "Epoch 655/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1133390.4500 - acc: 1.0000e-03 - val_loss: 1133242.1766 - val_acc: 1.0000e-03\n",
      "Epoch 656/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1133107.3310 - acc: 1.0000e-03 - val_loss: 1132956.5652 - val_acc: 1.0000e-03\n",
      "Epoch 657/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1132820.1220 - acc: 1.0000e-03 - val_loss: 1132672.5279 - val_acc: 1.0000e-03\n",
      "Epoch 658/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1132534.3300 - acc: 1.0000e-03 - val_loss: 1132384.0974 - val_acc: 1.0000e-03\n",
      "Epoch 659/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1132250.9800 - acc: 1.0000e-03 - val_loss: 1132098.6371 - val_acc: 1.0000e-03\n",
      "Epoch 660/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1131967.1620 - acc: 1.0000e-03 - val_loss: 1131816.3241 - val_acc: 1.0000e-03\n",
      "Epoch 661/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1131683.0470 - acc: 1.0000e-03 - val_loss: 1131534.5550 - val_acc: 1.0000e-03\n",
      "Epoch 662/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1131401.5080 - acc: 1.0000e-03 - val_loss: 1131251.1487 - val_acc: 1.0000e-03\n",
      "Epoch 663/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1131116.9340 - acc: 1.0000e-03 - val_loss: 1130965.7629 - val_acc: 1.0000e-03\n",
      "Epoch 664/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1130830.7460 - acc: 1.0000e-03 - val_loss: 1130683.2898 - val_acc: 1.0000e-03\n",
      "Epoch 665/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1130549.1440 - acc: 1.0000e-03 - val_loss: 1130396.4015 - val_acc: 1.0000e-03\n",
      "Epoch 666/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1130263.3800 - acc: 1.0000e-03 - val_loss: 1130115.7898 - val_acc: 1.0000e-03\n",
      "Epoch 667/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1129981.3390 - acc: 1.0000e-03 - val_loss: 1129830.9487 - val_acc: 1.0000e-03\n",
      "Epoch 668/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1129697.5060 - acc: 1.0000e-03 - val_loss: 1129548.5294 - val_acc: 1.0000e-03\n",
      "Epoch 669/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1129414.4980 - acc: 1.0000e-03 - val_loss: 1129266.2610 - val_acc: 1.0000e-03\n",
      "Epoch 670/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1129131.3920 - acc: 1.0000e-03 - val_loss: 1128981.4396 - val_acc: 1.0000e-03\n",
      "Epoch 671/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1128848.2185 - acc: 1.0000e-03 - val_loss: 1128700.5566 - val_acc: 1.0000e-03\n",
      "Epoch 672/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1128567.6880 - acc: 1.0000e-03 - val_loss: 1128418.3600 - val_acc: 1.0000e-03\n",
      "Epoch 673/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1128284.2310 - acc: 1.0000e-03 - val_loss: 1128134.8521 - val_acc: 1.0000e-03\n",
      "Epoch 674/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1128000.3870 - acc: 1.0000e-03 - val_loss: 1127852.4314 - val_acc: 1.0000e-03\n",
      "Epoch 675/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1127718.0960 - acc: 1.0000e-03 - val_loss: 1127566.8922 - val_acc: 1.0000e-03\n",
      "Epoch 676/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1127435.4220 - acc: 1.0000e-03 - val_loss: 1127288.2910 - val_acc: 1.0000e-03\n",
      "Epoch 677/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1127155.2090 - acc: 1.0000e-03 - val_loss: 1127004.7476 - val_acc: 1.0000e-03\n",
      "Epoch 678/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1126873.5075 - acc: 1.0000e-03 - val_loss: 1126724.1433 - val_acc: 1.0000e-03\n",
      "Epoch 679/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1126592.3360 - acc: 1.0000e-03 - val_loss: 1126442.2487 - val_acc: 1.0000e-03\n",
      "Epoch 680/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1126311.3670 - acc: 1.0000e-03 - val_loss: 1126161.0116 - val_acc: 1.0000e-03\n",
      "Epoch 681/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 1126029.6470 - acc: 1.0000e-03 - val_loss: 1125880.0588 - val_acc: 1.0000e-03\n",
      "Epoch 682/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1125748.1600 - acc: 1.0000e-03 - val_loss: 1125595.5918 - val_acc: 1.0000e-03\n",
      "Epoch 683/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1125463.9460 - acc: 1.0000e-03 - val_loss: 1125316.3428 - val_acc: 1.0000e-03\n",
      "Epoch 684/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1125181.2060 - acc: 1.0000e-03 - val_loss: 1125034.6739 - val_acc: 1.0000e-03\n",
      "Epoch 685/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1124900.3475 - acc: 1.0000e-03 - val_loss: 1124749.5591 - val_acc: 1.0000e-03\n",
      "Epoch 686/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 1124617.4040 - acc: 1.0000e-03 - val_loss: 1124470.1421 - val_acc: 1.0000e-03\n",
      "Epoch 687/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1124333.5550 - acc: 1.0000e-03 - val_loss: 1124187.2842 - val_acc: 1.0000e-03\n",
      "Epoch 688/1000\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 1124049.4800 - acc: 1.0000e-03 - val_loss: 1123901.6373 - val_acc: 1.0000e-03\n",
      "Epoch 689/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1123765.6060 - acc: 1.0000e-03 - val_loss: 1123616.9023 - val_acc: 1.0000e-03\n",
      "Epoch 690/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1123483.0960 - acc: 1.0000e-03 - val_loss: 1123331.8111 - val_acc: 1.0000e-03\n",
      "Epoch 691/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1123201.6630 - acc: 1.0000e-03 - val_loss: 1123052.0605 - val_acc: 1.0000e-03\n",
      "Epoch 692/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1122920.8730 - acc: 1.0000e-03 - val_loss: 1122774.3784 - val_acc: 1.0000e-03\n",
      "Epoch 693/1000\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 1122640.9140 - acc: 1.0000e-03 - val_loss: 1122490.7407 - val_acc: 1.0000e-03\n",
      "Epoch 694/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1122356.7205 - acc: 1.0000e-03 - val_loss: 1122210.6101 - val_acc: 1.0000e-03\n",
      "Epoch 695/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1122076.8460 - acc: 1.0000e-03 - val_loss: 1121926.8948 - val_acc: 1.0000e-03\n",
      "Epoch 696/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1121794.4945 - acc: 1.0000e-03 - val_loss: 1121644.7019 - val_acc: 1.0000e-03\n",
      "Epoch 697/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1121513.1080 - acc: 1.0000e-03 - val_loss: 1121367.0801 - val_acc: 1.0000e-03\n",
      "Epoch 698/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1121232.6125 - acc: 1.0000e-03 - val_loss: 1121080.8607 - val_acc: 1.0000e-03\n",
      "Epoch 699/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1120949.3740 - acc: 1.0000e-03 - val_loss: 1120799.8907 - val_acc: 1.0000e-03\n",
      "Epoch 700/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1120666.5210 - acc: 1.0000e-03 - val_loss: 1120518.5312 - val_acc: 1.0000e-03\n",
      "Epoch 701/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1120383.6120 - acc: 1.0000e-03 - val_loss: 1120233.3197 - val_acc: 1.0000e-03\n",
      "Epoch 702/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1120099.9960 - acc: 1.0000e-03 - val_loss: 1119950.7201 - val_acc: 1.0000e-03\n",
      "Epoch 703/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1119818.6040 - acc: 1.0000e-03 - val_loss: 1119668.8431 - val_acc: 1.0000e-03\n",
      "Epoch 704/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1119536.4625 - acc: 1.0000e-03 - val_loss: 1119388.5720 - val_acc: 1.0000e-03\n",
      "Epoch 705/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1119256.2610 - acc: 1.0000e-03 - val_loss: 1119106.9674 - val_acc: 1.0000e-03\n",
      "Epoch 706/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1118975.6450 - acc: 1.0000e-03 - val_loss: 1118825.4444 - val_acc: 1.0000e-03\n",
      "Epoch 707/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1118694.2100 - acc: 1.0000e-03 - val_loss: 1118542.9341 - val_acc: 1.0000e-03\n",
      "Epoch 708/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1118411.8170 - acc: 1.0000e-03 - val_loss: 1118267.4716 - val_acc: 1.0000e-03\n",
      "Epoch 709/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1118132.7920 - acc: 1.0000e-03 - val_loss: 1117983.1749 - val_acc: 1.0000e-03\n",
      "Epoch 710/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1117850.2880 - acc: 1.0000e-03 - val_loss: 1117702.7653 - val_acc: 1.0000e-03\n",
      "Epoch 711/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1117567.6860 - acc: 1.0000e-03 - val_loss: 1117418.6428 - val_acc: 1.0000e-03\n",
      "Epoch 712/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1117287.3545 - acc: 1.0000e-03 - val_loss: 1117137.3670 - val_acc: 1.0000e-03\n",
      "Epoch 713/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1117007.0315 - acc: 1.0000e-03 - val_loss: 1116862.7426 - val_acc: 1.0000e-03\n",
      "Epoch 714/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1116730.3100 - acc: 1.0000e-03 - val_loss: 1116583.1051 - val_acc: 1.0000e-03\n",
      "Epoch 715/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1116449.7900 - acc: 1.0000e-03 - val_loss: 1116303.2699 - val_acc: 1.0000e-03\n",
      "Epoch 716/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1116169.7330 - acc: 1.0000e-03 - val_loss: 1116019.8038 - val_acc: 1.0000e-03\n",
      "Epoch 717/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1115887.5420 - acc: 1.0000e-03 - val_loss: 1115742.5594 - val_acc: 1.0000e-03\n",
      "Epoch 718/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1115607.2030 - acc: 1.0000e-03 - val_loss: 1115458.8288 - val_acc: 1.0000e-03\n",
      "Epoch 719/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1115324.3480 - acc: 1.0000e-03 - val_loss: 1115180.5332 - val_acc: 1.0000e-03\n",
      "Epoch 720/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1115045.9930 - acc: 1.0000e-03 - val_loss: 1114897.7767 - val_acc: 1.0000e-03\n",
      "Epoch 721/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1114766.2540 - acc: 1.0000e-03 - val_loss: 1114617.5071 - val_acc: 1.0000e-03\n",
      "Epoch 722/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1114486.4130 - acc: 1.0000e-03 - val_loss: 1114338.5468 - val_acc: 1.0000e-03\n",
      "Epoch 723/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1114205.1380 - acc: 1.0000e-03 - val_loss: 1114056.9393 - val_acc: 1.0000e-03\n",
      "Epoch 724/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1113924.2610 - acc: 1.0000e-03 - val_loss: 1113773.6947 - val_acc: 1.0000e-03\n",
      "Epoch 725/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1113641.8755 - acc: 1.0000e-03 - val_loss: 1113496.7642 - val_acc: 1.0000e-03\n",
      "Epoch 726/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1113364.2400 - acc: 1.0000e-03 - val_loss: 1113215.7739 - val_acc: 1.0000e-03\n",
      "Epoch 727/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1113083.6500 - acc: 1.0000e-03 - val_loss: 1112938.7006 - val_acc: 1.0000e-03\n",
      "Epoch 728/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1112805.2860 - acc: 1.0000e-03 - val_loss: 1112658.7372 - val_acc: 1.0000e-03\n",
      "Epoch 729/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1112524.7080 - acc: 1.0000e-03 - val_loss: 1112377.1613 - val_acc: 1.0000e-03\n",
      "Epoch 730/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1112244.7360 - acc: 1.0000e-03 - val_loss: 1112095.2527 - val_acc: 1.0000e-03\n",
      "Epoch 731/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1111962.8435 - acc: 1.0000e-03 - val_loss: 1111814.9176 - val_acc: 1.0000e-03\n",
      "Epoch 732/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1111683.0120 - acc: 1.0000e-03 - val_loss: 1111535.7511 - val_acc: 1.0000e-03\n",
      "Epoch 733/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1111401.7580 - acc: 1.0000e-03 - val_loss: 1111252.2309 - val_acc: 1.0000e-03\n",
      "Epoch 734/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1111121.2710 - acc: 1.0000e-03 - val_loss: 1110977.2146 - val_acc: 1.0000e-03\n",
      "Epoch 735/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1110842.6840 - acc: 1.0000e-03 - val_loss: 1110694.9177 - val_acc: 1.0000e-03\n",
      "Epoch 736/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1110560.8640 - acc: 1.0000e-03 - val_loss: 1110414.1939 - val_acc: 1.0000e-03\n",
      "Epoch 737/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1110280.5010 - acc: 1.0000e-03 - val_loss: 1110130.9187 - val_acc: 1.0000e-03\n",
      "Epoch 738/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1109999.1960 - acc: 1.0000e-03 - val_loss: 1109851.0749 - val_acc: 1.0000e-03\n",
      "Epoch 739/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1109720.0360 - acc: 1.0000e-03 - val_loss: 1109573.0446 - val_acc: 1.0000e-03\n",
      "Epoch 740/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1109440.6850 - acc: 1.0000e-03 - val_loss: 1109292.0870 - val_acc: 1.0000e-03\n",
      "Epoch 741/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1109160.3780 - acc: 1.0000e-03 - val_loss: 1109013.7925 - val_acc: 1.0000e-03\n",
      "Epoch 742/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1108880.0520 - acc: 1.0000e-03 - val_loss: 1108733.5034 - val_acc: 1.0000e-03\n",
      "Epoch 743/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1108598.7550 - acc: 1.0000e-03 - val_loss: 1108449.6275 - val_acc: 1.0000e-03\n",
      "Epoch 744/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1108316.9380 - acc: 1.0000e-03 - val_loss: 1108171.8237 - val_acc: 1.0000e-03\n",
      "Epoch 745/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1108039.3690 - acc: 1.0000e-03 - val_loss: 1107891.0706 - val_acc: 1.0000e-03\n",
      "Epoch 746/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1107758.8430 - acc: 1.0000e-03 - val_loss: 1107611.4350 - val_acc: 1.0000e-03\n",
      "Epoch 747/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1107480.2120 - acc: 1.0000e-03 - val_loss: 1107333.2254 - val_acc: 1.0000e-03\n",
      "Epoch 748/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1107200.8730 - acc: 1.0000e-03 - val_loss: 1107055.2465 - val_acc: 1.0000e-03\n",
      "Epoch 749/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1106923.1650 - acc: 1.0000e-03 - val_loss: 1106776.5462 - val_acc: 1.0000e-03\n",
      "Epoch 750/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1106645.3070 - acc: 1.0000e-03 - val_loss: 1106496.4915 - val_acc: 1.0000e-03\n",
      "Epoch 751/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1106364.8080 - acc: 1.0000e-03 - val_loss: 1106218.5688 - val_acc: 1.0000e-03\n",
      "Epoch 752/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1106084.2415 - acc: 1.0000e-03 - val_loss: 1105936.4485 - val_acc: 1.0000e-03\n",
      "Epoch 753/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1105804.4010 - acc: 1.0000e-03 - val_loss: 1105659.5274 - val_acc: 1.0000e-03\n",
      "Epoch 754/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1105525.3020 - acc: 1.0000e-03 - val_loss: 1105377.8948 - val_acc: 1.0000e-03\n",
      "Epoch 755/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1105246.5240 - acc: 1.0000e-03 - val_loss: 1105098.9387 - val_acc: 1.0000e-03\n",
      "Epoch 756/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1104966.4710 - acc: 1.0000e-03 - val_loss: 1104819.4904 - val_acc: 1.0000e-03\n",
      "Epoch 757/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1104685.6610 - acc: 1.0000e-03 - val_loss: 1104540.3585 - val_acc: 1.0000e-03\n",
      "Epoch 758/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1104407.5940 - acc: 1.0000e-03 - val_loss: 1104255.9049 - val_acc: 1.0000e-03\n",
      "Epoch 759/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1104126.3510 - acc: 1.0000e-03 - val_loss: 1103978.0334 - val_acc: 1.0000e-03\n",
      "Epoch 760/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1103847.6300 - acc: 1.0000e-03 - val_loss: 1103703.5667 - val_acc: 1.0000e-03\n",
      "Epoch 761/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1103569.6460 - acc: 1.0000e-03 - val_loss: 1103422.4421 - val_acc: 1.0000e-03\n",
      "Epoch 762/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1103289.6145 - acc: 1.0000e-03 - val_loss: 1103139.5078 - val_acc: 1.0000e-03\n",
      "Epoch 763/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1103009.6880 - acc: 1.0000e-03 - val_loss: 1102865.4770 - val_acc: 1.0000e-03\n",
      "Epoch 764/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1102733.1017 - acc: 1.0000e-03 - val_loss: 1102583.4407 - val_acc: 1.0000e-03\n",
      "Epoch 765/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1102454.4755 - acc: 1.0000e-03 - val_loss: 1102310.5340 - val_acc: 1.0000e-03\n",
      "Epoch 766/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1102178.8270 - acc: 1.0000e-03 - val_loss: 1102031.1798 - val_acc: 1.0000e-03\n",
      "Epoch 767/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1101900.7300 - acc: 1.0000e-03 - val_loss: 1101753.8257 - val_acc: 1.0000e-03\n",
      "Epoch 768/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1101622.0770 - acc: 1.0000e-03 - val_loss: 1101474.8287 - val_acc: 1.0000e-03\n",
      "Epoch 769/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1101344.2040 - acc: 1.0000e-03 - val_loss: 1101197.9444 - val_acc: 1.0000e-03\n",
      "Epoch 770/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1101066.0410 - acc: 1.0000e-03 - val_loss: 1100918.4333 - val_acc: 1.0000e-03\n",
      "Epoch 771/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1100788.0470 - acc: 1.0000e-03 - val_loss: 1100640.7697 - val_acc: 1.0000e-03\n",
      "Epoch 772/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1100509.6750 - acc: 1.0000e-03 - val_loss: 1100364.8390 - val_acc: 1.0000e-03\n",
      "Epoch 773/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1100233.3710 - acc: 1.0000e-03 - val_loss: 1100086.8698 - val_acc: 1.0000e-03\n",
      "Epoch 774/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1099956.1900 - acc: 1.0000e-03 - val_loss: 1099805.1897 - val_acc: 1.0000e-03\n",
      "Epoch 775/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1099674.5620 - acc: 1.0000e-03 - val_loss: 1099530.0596 - val_acc: 1.0000e-03\n",
      "Epoch 776/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1099397.7265 - acc: 1.0000e-03 - val_loss: 1099250.7362 - val_acc: 1.0000e-03\n",
      "Epoch 777/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1099120.1180 - acc: 1.0000e-03 - val_loss: 1098973.2475 - val_acc: 1.0000e-03\n",
      "Epoch 778/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1098843.0190 - acc: 1.0000e-03 - val_loss: 1098696.7814 - val_acc: 1.0000e-03\n",
      "Epoch 779/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1098565.3560 - acc: 1.0000e-03 - val_loss: 1098417.0023 - val_acc: 1.0000e-03\n",
      "Epoch 780/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1098285.9300 - acc: 1.0000e-03 - val_loss: 1098136.1943 - val_acc: 1.0000e-03\n",
      "Epoch 781/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1098004.9960 - acc: 1.0000e-03 - val_loss: 1097859.5042 - val_acc: 1.0000e-03\n",
      "Epoch 782/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1097728.0000 - acc: 1.0000e-03 - val_loss: 1097582.4563 - val_acc: 1.0000e-03\n",
      "Epoch 783/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1097452.5635 - acc: 1.0000e-03 - val_loss: 1097304.7828 - val_acc: 1.0000e-03\n",
      "Epoch 784/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1097175.0120 - acc: 1.0000e-03 - val_loss: 1097028.1948 - val_acc: 1.0000e-03\n",
      "Epoch 785/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1096897.8550 - acc: 1.0000e-03 - val_loss: 1096750.9983 - val_acc: 1.0000e-03\n",
      "Epoch 786/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1096622.7733 - acc: 1.0000e-03 - val_loss: 1096475.9225 - val_acc: 1.0000e-03\n",
      "Epoch 787/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1096347.2040 - acc: 1.0000e-03 - val_loss: 1096202.9444 - val_acc: 1.0000e-03\n",
      "Epoch 788/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1096070.8920 - acc: 1.0000e-03 - val_loss: 1095923.0820 - val_acc: 1.0000e-03\n",
      "Epoch 789/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1095793.3780 - acc: 1.0000e-03 - val_loss: 1095646.5068 - val_acc: 1.0000e-03\n",
      "Epoch 790/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1095514.8875 - acc: 1.0000e-03 - val_loss: 1095369.3740 - val_acc: 1.0000e-03\n",
      "Epoch 791/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1095239.2500 - acc: 1.0000e-03 - val_loss: 1095090.2021 - val_acc: 1.0000e-03\n",
      "Epoch 792/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1094963.3700 - acc: 1.0000e-03 - val_loss: 1094816.0829 - val_acc: 1.0000e-03\n",
      "Epoch 793/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1094686.3660 - acc: 1.0000e-03 - val_loss: 1094535.7231 - val_acc: 1.0000e-03\n",
      "Epoch 794/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1094406.3880 - acc: 1.0000e-03 - val_loss: 1094261.2137 - val_acc: 1.0000e-03\n",
      "Epoch 795/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1094130.4040 - acc: 1.0000e-03 - val_loss: 1093983.8340 - val_acc: 1.0000e-03\n",
      "Epoch 796/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1093852.1980 - acc: 1.0000e-03 - val_loss: 1093705.4394 - val_acc: 1.0000e-03\n",
      "Epoch 797/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1093575.5990 - acc: 1.0000e-03 - val_loss: 1093431.6370 - val_acc: 1.0000e-03\n",
      "Epoch 798/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1093300.5080 - acc: 1.0000e-03 - val_loss: 1093154.8685 - val_acc: 1.0000e-03\n",
      "Epoch 799/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1093023.4100 - acc: 1.0000e-03 - val_loss: 1092878.8112 - val_acc: 1.0000e-03\n",
      "Epoch 800/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1092746.2160 - acc: 1.0000e-03 - val_loss: 1092598.2824 - val_acc: 1.0000e-03\n",
      "Epoch 801/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1092468.1110 - acc: 1.0000e-03 - val_loss: 1092323.5718 - val_acc: 1.0000e-03\n",
      "Epoch 802/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1092191.9105 - acc: 1.0000e-03 - val_loss: 1092045.4978 - val_acc: 1.0000e-03\n",
      "Epoch 803/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1091915.4440 - acc: 1.0000e-03 - val_loss: 1091768.3531 - val_acc: 1.0000e-03\n",
      "Epoch 804/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1091638.0860 - acc: 1.0000e-03 - val_loss: 1091489.7101 - val_acc: 1.0000e-03\n",
      "Epoch 805/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1091361.6580 - acc: 1.0000e-03 - val_loss: 1091217.9956 - val_acc: 1.0000e-03\n",
      "Epoch 806/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1091087.4260 - acc: 1.0000e-03 - val_loss: 1090939.2691 - val_acc: 1.0000e-03\n",
      "Epoch 807/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1090809.8080 - acc: 1.0000e-03 - val_loss: 1090665.2562 - val_acc: 1.0000e-03\n",
      "Epoch 808/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1090534.2710 - acc: 1.0000e-03 - val_loss: 1090386.2224 - val_acc: 1.0000e-03\n",
      "Epoch 809/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1090254.2430 - acc: 1.0000e-03 - val_loss: 1090110.8233 - val_acc: 1.0000e-03\n",
      "Epoch 810/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1089977.7700 - acc: 1.0000e-03 - val_loss: 1089832.4587 - val_acc: 1.0000e-03\n",
      "Epoch 811/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1089699.9680 - acc: 1.0000e-03 - val_loss: 1089556.3224 - val_acc: 1.0000e-03\n",
      "Epoch 812/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1089423.6790 - acc: 1.0000e-03 - val_loss: 1089274.7285 - val_acc: 1.0000e-03\n",
      "Epoch 813/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1089144.4020 - acc: 1.0000e-03 - val_loss: 1089000.4082 - val_acc: 1.0000e-03\n",
      "Epoch 814/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1088869.3550 - acc: 1.0000e-03 - val_loss: 1088723.5005 - val_acc: 1.0000e-03\n",
      "Epoch 815/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1088594.2960 - acc: 1.0000e-03 - val_loss: 1088448.3268 - val_acc: 1.0000e-03\n",
      "Epoch 816/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1088319.9990 - acc: 1.0000e-03 - val_loss: 1088174.1676 - val_acc: 1.0000e-03\n",
      "Epoch 817/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1088044.0600 - acc: 1.0000e-03 - val_loss: 1087899.3456 - val_acc: 1.0000e-03\n",
      "Epoch 818/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1087767.6740 - acc: 1.0000e-03 - val_loss: 1087623.0849 - val_acc: 1.0000e-03\n",
      "Epoch 819/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1087491.3185 - acc: 1.0000e-03 - val_loss: 1087343.2850 - val_acc: 1.0000e-03\n",
      "Epoch 820/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1087214.5650 - acc: 1.0000e-03 - val_loss: 1087069.5034 - val_acc: 1.0000e-03\n",
      "Epoch 821/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1086940.5060 - acc: 1.0000e-03 - val_loss: 1086793.3852 - val_acc: 1.0000e-03\n",
      "Epoch 822/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1086662.9880 - acc: 1.0000e-03 - val_loss: 1086519.1871 - val_acc: 1.0000e-03\n",
      "Epoch 823/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1086387.0720 - acc: 1.0000e-03 - val_loss: 1086241.6942 - val_acc: 1.0000e-03\n",
      "Epoch 824/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1086111.3685 - acc: 1.0000e-03 - val_loss: 1085967.8358 - val_acc: 1.0000e-03\n",
      "Epoch 825/1000\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 1085837.3815 - acc: 1.0000e-03 - val_loss: 1085691.2915 - val_acc: 1.0000e-03\n",
      "Epoch 826/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1085561.5815 - acc: 1.0000e-03 - val_loss: 1085416.8839 - val_acc: 1.0000e-03\n",
      "Epoch 827/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1085287.4380 - acc: 1.0000e-03 - val_loss: 1085141.6487 - val_acc: 1.0000e-03\n",
      "Epoch 828/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1085012.4690 - acc: 1.0000e-03 - val_loss: 1084867.9710 - val_acc: 1.0000e-03\n",
      "Epoch 829/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1084737.7680 - acc: 1.0000e-03 - val_loss: 1084589.7143 - val_acc: 1.0000e-03\n",
      "Epoch 830/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1084461.8120 - acc: 1.0000e-03 - val_loss: 1084317.6498 - val_acc: 1.0000e-03\n",
      "Epoch 831/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1084187.7810 - acc: 1.0000e-03 - val_loss: 1084044.1392 - val_acc: 1.0000e-03\n",
      "Epoch 832/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1083913.3325 - acc: 1.0000e-03 - val_loss: 1083767.9125 - val_acc: 1.0000e-03\n",
      "Epoch 833/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1083638.1855 - acc: 1.0000e-03 - val_loss: 1083494.6689 - val_acc: 1.0000e-03\n",
      "Epoch 834/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1083365.8940 - acc: 1.0000e-03 - val_loss: 1083219.5111 - val_acc: 1.0000e-03\n",
      "Epoch 835/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1083088.8200 - acc: 1.0000e-03 - val_loss: 1082943.8849 - val_acc: 1.0000e-03\n",
      "Epoch 836/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1082815.2020 - acc: 1.0000e-03 - val_loss: 1082667.6754 - val_acc: 1.0000e-03\n",
      "Epoch 837/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1082537.8260 - acc: 1.0000e-03 - val_loss: 1082392.4767 - val_acc: 1.0000e-03\n",
      "Epoch 838/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1082262.2265 - acc: 1.0000e-03 - val_loss: 1082113.9673 - val_acc: 1.0000e-03\n",
      "Epoch 839/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1081985.0260 - acc: 1.0000e-03 - val_loss: 1081843.6037 - val_acc: 1.0000e-03\n",
      "Epoch 840/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1081713.6400 - acc: 1.0000e-03 - val_loss: 1081568.2111 - val_acc: 1.0000e-03\n",
      "Epoch 841/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1081437.4100 - acc: 1.0000e-03 - val_loss: 1081294.2953 - val_acc: 1.0000e-03\n",
      "Epoch 842/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1081164.9800 - acc: 1.0000e-03 - val_loss: 1081018.9389 - val_acc: 1.0000e-03\n",
      "Epoch 843/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1080890.7910 - acc: 1.0000e-03 - val_loss: 1080747.0249 - val_acc: 1.0000e-03\n",
      "Epoch 844/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1080617.9510 - acc: 1.0000e-03 - val_loss: 1080472.4791 - val_acc: 1.0000e-03\n",
      "Epoch 845/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1080342.6605 - acc: 1.0000e-03 - val_loss: 1080198.8170 - val_acc: 1.0000e-03\n",
      "Epoch 846/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1080069.3990 - acc: 1.0000e-03 - val_loss: 1079924.6816 - val_acc: 1.0000e-03\n",
      "Epoch 847/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1079793.5840 - acc: 1.0000e-03 - val_loss: 1079646.7325 - val_acc: 1.0000e-03\n",
      "Epoch 848/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1079517.9040 - acc: 1.0000e-03 - val_loss: 1079371.6320 - val_acc: 1.0000e-03\n",
      "Epoch 849/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1079241.1890 - acc: 1.0000e-03 - val_loss: 1079097.5072 - val_acc: 1.0000e-03\n",
      "Epoch 850/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1078965.6690 - acc: 1.0000e-03 - val_loss: 1078820.9967 - val_acc: 1.0000e-03\n",
      "Epoch 851/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1078691.8005 - acc: 1.0000e-03 - val_loss: 1078544.8461 - val_acc: 1.0000e-03\n",
      "Epoch 852/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1078417.8950 - acc: 1.0000e-03 - val_loss: 1078273.1504 - val_acc: 1.0000e-03\n",
      "Epoch 853/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1078144.7660 - acc: 1.0000e-03 - val_loss: 1078002.9920 - val_acc: 1.0000e-03\n",
      "Epoch 854/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1077872.2320 - acc: 1.0000e-03 - val_loss: 1077728.2099 - val_acc: 1.0000e-03\n",
      "Epoch 855/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1077595.9050 - acc: 1.0000e-03 - val_loss: 1077449.4217 - val_acc: 1.0000e-03\n",
      "Epoch 856/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1077319.5572 - acc: 1.0000e-03 - val_loss: 1077176.1346 - val_acc: 1.0000e-03\n",
      "Epoch 857/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1077047.7940 - acc: 1.0000e-03 - val_loss: 1076903.9085 - val_acc: 1.0000e-03\n",
      "Epoch 858/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1076774.3865 - acc: 1.0000e-03 - val_loss: 1076627.4164 - val_acc: 1.0000e-03\n",
      "Epoch 859/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1076500.3240 - acc: 1.0000e-03 - val_loss: 1076356.6331 - val_acc: 1.0000e-03\n",
      "Epoch 860/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1076226.2290 - acc: 1.0000e-03 - val_loss: 1076081.1132 - val_acc: 1.0000e-03\n",
      "Epoch 861/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1075949.3000 - acc: 1.0000e-03 - val_loss: 1075803.8355 - val_acc: 1.0000e-03\n",
      "Epoch 862/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1075674.2555 - acc: 1.0000e-03 - val_loss: 1075528.0721 - val_acc: 1.0000e-03\n",
      "Epoch 863/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1075399.7985 - acc: 1.0000e-03 - val_loss: 1075254.5127 - val_acc: 1.0000e-03\n",
      "Epoch 864/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1075125.9860 - acc: 1.0000e-03 - val_loss: 1074983.9400 - val_acc: 1.0000e-03\n",
      "Epoch 865/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1074851.9700 - acc: 1.0000e-03 - val_loss: 1074705.2650 - val_acc: 1.0000e-03\n",
      "Epoch 866/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1074576.3500 - acc: 1.0000e-03 - val_loss: 1074431.9824 - val_acc: 1.0000e-03\n",
      "Epoch 867/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1074303.0540 - acc: 1.0000e-03 - val_loss: 1074156.0191 - val_acc: 1.0000e-03\n",
      "Epoch 868/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1074027.1390 - acc: 1.0000e-03 - val_loss: 1073882.2845 - val_acc: 1.0000e-03\n",
      "Epoch 869/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1073753.5790 - acc: 1.0000e-03 - val_loss: 1073611.1437 - val_acc: 1.0000e-03\n",
      "Epoch 870/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1073481.8620 - acc: 1.0000e-03 - val_loss: 1073334.9789 - val_acc: 1.0000e-03\n",
      "Epoch 871/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1073208.8120 - acc: 1.0000e-03 - val_loss: 1073065.0570 - val_acc: 1.0000e-03\n",
      "Epoch 872/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1072934.8100 - acc: 1.0000e-03 - val_loss: 1072788.7483 - val_acc: 1.0000e-03\n",
      "Epoch 873/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1072660.1860 - acc: 1.0000e-03 - val_loss: 1072516.5545 - val_acc: 1.0000e-03\n",
      "Epoch 874/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1072387.8440 - acc: 1.0000e-03 - val_loss: 1072242.9248 - val_acc: 1.0000e-03\n",
      "Epoch 875/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1072113.8785 - acc: 1.0000e-03 - val_loss: 1071967.3872 - val_acc: 1.0000e-03\n",
      "Epoch 876/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1071840.1210 - acc: 1.0000e-03 - val_loss: 1071698.7105 - val_acc: 1.0000e-03\n",
      "Epoch 877/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1071569.5640 - acc: 1.0000e-03 - val_loss: 1071425.7127 - val_acc: 1.0000e-03\n",
      "Epoch 878/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1071294.7965 - acc: 1.0000e-03 - val_loss: 1071153.0557 - val_acc: 1.0000e-03\n",
      "Epoch 879/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1071022.4180 - acc: 1.0000e-03 - val_loss: 1070879.6261 - val_acc: 1.0000e-03\n",
      "Epoch 880/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1070747.5020 - acc: 1.0000e-03 - val_loss: 1070601.9419 - val_acc: 1.0000e-03\n",
      "Epoch 881/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1070473.3730 - acc: 1.0000e-03 - val_loss: 1070331.4088 - val_acc: 1.0000e-03\n",
      "Epoch 882/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1070201.6880 - acc: 1.0000e-03 - val_loss: 1070057.9488 - val_acc: 1.0000e-03\n",
      "Epoch 883/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1069926.9890 - acc: 1.0000e-03 - val_loss: 1069783.4845 - val_acc: 1.0000e-03\n",
      "Epoch 884/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1069654.1480 - acc: 1.0000e-03 - val_loss: 1069514.1782 - val_acc: 1.0000e-03\n",
      "Epoch 885/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1069381.0270 - acc: 1.0000e-03 - val_loss: 1069235.2789 - val_acc: 1.0000e-03\n",
      "Epoch 886/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1069103.7830 - acc: 1.0000e-03 - val_loss: 1068959.4587 - val_acc: 1.0000e-03\n",
      "Epoch 887/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1068831.9430 - acc: 1.0000e-03 - val_loss: 1068686.8521 - val_acc: 1.0000e-03\n",
      "Epoch 888/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1068559.3725 - acc: 1.0000e-03 - val_loss: 1068416.6014 - val_acc: 1.0000e-03\n",
      "Epoch 889/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1068289.6875 - acc: 1.0000e-03 - val_loss: 1068146.8501 - val_acc: 1.0000e-03\n",
      "Epoch 890/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1068018.5485 - acc: 1.0000e-03 - val_loss: 1067876.5300 - val_acc: 1.0000e-03\n",
      "Epoch 891/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1067747.9680 - acc: 1.0000e-03 - val_loss: 1067605.8747 - val_acc: 1.0000e-03\n",
      "Epoch 892/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1067473.9605 - acc: 1.0000e-03 - val_loss: 1067332.1930 - val_acc: 1.0000e-03\n",
      "Epoch 893/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1067202.6145 - acc: 1.0000e-03 - val_loss: 1067056.7967 - val_acc: 1.0000e-03\n",
      "Epoch 894/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1066929.5630 - acc: 1.0000e-03 - val_loss: 1066786.3707 - val_acc: 1.0000e-03\n",
      "Epoch 895/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1066657.4325 - acc: 1.0000e-03 - val_loss: 1066514.9225 - val_acc: 1.0000e-03\n",
      "Epoch 896/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1066385.9050 - acc: 1.0000e-03 - val_loss: 1066244.3996 - val_acc: 1.0000e-03\n",
      "Epoch 897/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1066114.3680 - acc: 1.0000e-03 - val_loss: 1065968.9351 - val_acc: 1.0000e-03\n",
      "Epoch 898/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1065840.6195 - acc: 1.0000e-03 - val_loss: 1065696.9221 - val_acc: 1.0000e-03\n",
      "Epoch 899/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1065570.8320 - acc: 1.0000e-03 - val_loss: 1065426.2483 - val_acc: 1.0000e-03\n",
      "Epoch 900/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1065298.8670 - acc: 1.0000e-03 - val_loss: 1065157.4619 - val_acc: 1.0000e-03\n",
      "Epoch 901/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1065027.2120 - acc: 1.0000e-03 - val_loss: 1064882.0101 - val_acc: 1.0000e-03\n",
      "Epoch 902/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1064753.1480 - acc: 1.0000e-03 - val_loss: 1064611.7300 - val_acc: 1.0000e-03\n",
      "Epoch 903/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1064481.8340 - acc: 1.0000e-03 - val_loss: 1064333.7897 - val_acc: 1.0000e-03\n",
      "Epoch 904/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1064207.6740 - acc: 1.0000e-03 - val_loss: 1064064.6015 - val_acc: 1.0000e-03\n",
      "Epoch 905/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1063934.6320 - acc: 1.0000e-03 - val_loss: 1063792.3467 - val_acc: 1.0000e-03\n",
      "Epoch 906/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1063663.6680 - acc: 1.0000e-03 - val_loss: 1063521.5438 - val_acc: 1.0000e-03\n",
      "Epoch 907/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1063390.3030 - acc: 1.0000e-03 - val_loss: 1063245.1337 - val_acc: 1.0000e-03\n",
      "Epoch 908/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1063118.2790 - acc: 1.0000e-03 - val_loss: 1062973.8674 - val_acc: 1.0000e-03\n",
      "Epoch 909/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1062847.3620 - acc: 1.0000e-03 - val_loss: 1062703.6452 - val_acc: 1.0000e-03\n",
      "Epoch 910/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1062576.2910 - acc: 1.0000e-03 - val_loss: 1062433.5851 - val_acc: 1.0000e-03\n",
      "Epoch 911/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1062305.4345 - acc: 1.0000e-03 - val_loss: 1062162.8247 - val_acc: 1.0000e-03\n",
      "Epoch 912/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1062034.3520 - acc: 1.0000e-03 - val_loss: 1061891.7617 - val_acc: 1.0000e-03\n",
      "Epoch 913/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1061762.1625 - acc: 1.0000e-03 - val_loss: 1061618.5390 - val_acc: 1.0000e-03\n",
      "Epoch 914/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1061491.1235 - acc: 1.0000e-03 - val_loss: 1061346.2691 - val_acc: 1.0000e-03\n",
      "Epoch 915/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1061219.4450 - acc: 1.0000e-03 - val_loss: 1061079.2322 - val_acc: 1.0000e-03\n",
      "Epoch 916/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1060950.5490 - acc: 1.0000e-03 - val_loss: 1060807.2768 - val_acc: 1.0000e-03\n",
      "Epoch 917/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1060676.9070 - acc: 1.0000e-03 - val_loss: 1060534.1371 - val_acc: 1.0000e-03\n",
      "Epoch 918/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1060404.9540 - acc: 1.0000e-03 - val_loss: 1060262.5305 - val_acc: 1.0000e-03\n",
      "Epoch 919/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1060132.8630 - acc: 1.0000e-03 - val_loss: 1059987.2450 - val_acc: 1.0000e-03\n",
      "Epoch 920/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1059860.7440 - acc: 1.0000e-03 - val_loss: 1059721.2416 - val_acc: 1.0000e-03\n",
      "Epoch 921/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1059591.9550 - acc: 1.0000e-03 - val_loss: 1059449.2571 - val_acc: 1.0000e-03\n",
      "Epoch 922/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1059321.7365 - acc: 1.0000e-03 - val_loss: 1059178.8187 - val_acc: 1.0000e-03\n",
      "Epoch 923/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1059051.9060 - acc: 1.0000e-03 - val_loss: 1058910.4792 - val_acc: 1.0000e-03\n",
      "Epoch 924/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1058782.6740 - acc: 1.0000e-03 - val_loss: 1058640.1886 - val_acc: 1.0000e-03\n",
      "Epoch 925/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1058513.0250 - acc: 1.0000e-03 - val_loss: 1058369.1503 - val_acc: 1.0000e-03\n",
      "Epoch 926/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1058241.3170 - acc: 1.0000e-03 - val_loss: 1058097.0659 - val_acc: 1.0000e-03\n",
      "Epoch 927/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1057970.8900 - acc: 1.0000e-03 - val_loss: 1057828.3649 - val_acc: 1.0000e-03\n",
      "Epoch 928/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1057699.9580 - acc: 1.0000e-03 - val_loss: 1057558.5261 - val_acc: 1.0000e-03\n",
      "Epoch 929/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1057428.8940 - acc: 1.0000e-03 - val_loss: 1057286.6871 - val_acc: 1.0000e-03\n",
      "Epoch 930/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1057157.1720 - acc: 1.0000e-03 - val_loss: 1057013.6770 - val_acc: 1.0000e-03\n",
      "Epoch 931/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1056886.6970 - acc: 1.0000e-03 - val_loss: 1056744.3267 - val_acc: 1.0000e-03\n",
      "Epoch 932/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1056615.7632 - acc: 1.0000e-03 - val_loss: 1056471.5372 - val_acc: 1.0000e-03\n",
      "Epoch 933/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1056345.2760 - acc: 1.0000e-03 - val_loss: 1056203.5113 - val_acc: 1.0000e-03\n",
      "Epoch 934/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1056074.7200 - acc: 1.0000e-03 - val_loss: 1055933.1499 - val_acc: 1.0000e-03\n",
      "Epoch 935/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1055804.1800 - acc: 1.0000e-03 - val_loss: 1055660.8954 - val_acc: 1.0000e-03\n",
      "Epoch 936/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1055531.9110 - acc: 1.0000e-03 - val_loss: 1055389.4141 - val_acc: 1.0000e-03\n",
      "Epoch 937/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1055261.8460 - acc: 1.0000e-03 - val_loss: 1055117.6195 - val_acc: 1.0000e-03\n",
      "Epoch 938/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1054991.2370 - acc: 1.0000e-03 - val_loss: 1054848.1752 - val_acc: 1.0000e-03\n",
      "Epoch 939/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1054719.8280 - acc: 1.0000e-03 - val_loss: 1054577.1373 - val_acc: 1.0000e-03\n",
      "Epoch 940/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1054448.7582 - acc: 1.0000e-03 - val_loss: 1054307.5359 - val_acc: 1.0000e-03\n",
      "Epoch 941/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1054180.1420 - acc: 1.0000e-03 - val_loss: 1054039.4211 - val_acc: 1.0000e-03\n",
      "Epoch 942/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1053909.8562 - acc: 1.0000e-03 - val_loss: 1053768.3347 - val_acc: 1.0000e-03\n",
      "Epoch 943/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1053641.1780 - acc: 1.0000e-03 - val_loss: 1053499.0138 - val_acc: 1.0000e-03\n",
      "Epoch 944/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1053370.6730 - acc: 1.0000e-03 - val_loss: 1053224.9390 - val_acc: 1.0000e-03\n",
      "Epoch 945/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1053098.4970 - acc: 1.0000e-03 - val_loss: 1052957.9483 - val_acc: 1.0000e-03\n",
      "Epoch 946/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1052829.1550 - acc: 1.0000e-03 - val_loss: 1052685.8115 - val_acc: 1.0000e-03\n",
      "Epoch 947/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1052557.2720 - acc: 1.0000e-03 - val_loss: 1052415.5459 - val_acc: 1.0000e-03\n",
      "Epoch 948/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1052288.3464 - acc: 1.0000e-03 - val_loss: 1052145.8780 - val_acc: 1.0000e-03\n",
      "Epoch 949/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1052020.8780 - acc: 1.0000e-03 - val_loss: 1051880.1668 - val_acc: 1.0000e-03\n",
      "Epoch 950/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1051751.0000 - acc: 1.0000e-03 - val_loss: 1051608.3205 - val_acc: 1.0000e-03\n",
      "Epoch 951/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1051482.5065 - acc: 1.0000e-03 - val_loss: 1051338.7173 - val_acc: 1.0000e-03\n",
      "Epoch 952/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1051213.1330 - acc: 1.0000e-03 - val_loss: 1051071.1425 - val_acc: 1.0000e-03\n",
      "Epoch 953/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1050943.3790 - acc: 1.0000e-03 - val_loss: 1050804.9084 - val_acc: 1.0000e-03\n",
      "Epoch 954/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1050675.7815 - acc: 1.0000e-03 - val_loss: 1050531.1037 - val_acc: 1.0000e-03\n",
      "Epoch 955/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1050405.4860 - acc: 1.0000e-03 - val_loss: 1050261.9957 - val_acc: 1.0000e-03\n",
      "Epoch 956/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1050137.1740 - acc: 1.0000e-03 - val_loss: 1049994.9544 - val_acc: 1.0000e-03\n",
      "Epoch 957/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1049867.2340 - acc: 1.0000e-03 - val_loss: 1049724.1412 - val_acc: 1.0000e-03\n",
      "Epoch 958/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1049596.5250 - acc: 1.0000e-03 - val_loss: 1049456.9387 - val_acc: 1.0000e-03\n",
      "Epoch 959/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1049328.9845 - acc: 1.0000e-03 - val_loss: 1049187.2322 - val_acc: 1.0000e-03\n",
      "Epoch 960/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1049059.8220 - acc: 1.0000e-03 - val_loss: 1048917.2224 - val_acc: 1.0000e-03\n",
      "Epoch 961/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1048789.7770 - acc: 1.0000e-03 - val_loss: 1048647.9946 - val_acc: 1.0000e-03\n",
      "Epoch 962/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1048519.7770 - acc: 1.0000e-03 - val_loss: 1048374.2370 - val_acc: 1.0000e-03\n",
      "Epoch 963/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1048248.5933 - acc: 1.0000e-03 - val_loss: 1048105.7705 - val_acc: 1.0000e-03\n",
      "Epoch 964/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1047979.5580 - acc: 1.0000e-03 - val_loss: 1047843.6015 - val_acc: 1.0000e-03\n",
      "Epoch 965/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1047713.9700 - acc: 1.0000e-03 - val_loss: 1047567.9140 - val_acc: 1.0000e-03\n",
      "Epoch 966/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1047441.5200 - acc: 1.0000e-03 - val_loss: 1047300.6458 - val_acc: 1.0000e-03\n",
      "Epoch 967/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1047172.8915 - acc: 1.0000e-03 - val_loss: 1047030.4718 - val_acc: 1.0000e-03\n",
      "Epoch 968/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1046904.5695 - acc: 1.0000e-03 - val_loss: 1046762.5826 - val_acc: 1.0000e-03\n",
      "Epoch 969/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1046636.5360 - acc: 1.0000e-03 - val_loss: 1046495.5719 - val_acc: 1.0000e-03\n",
      "Epoch 970/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1046368.2930 - acc: 1.0000e-03 - val_loss: 1046229.3709 - val_acc: 1.0000e-03\n",
      "Epoch 971/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1046099.1760 - acc: 1.0000e-03 - val_loss: 1045957.9039 - val_acc: 1.0000e-03\n",
      "Epoch 972/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1045829.9160 - acc: 1.0000e-03 - val_loss: 1045686.3172 - val_acc: 1.0000e-03\n",
      "Epoch 973/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1045558.8080 - acc: 1.0000e-03 - val_loss: 1045419.1696 - val_acc: 1.0000e-03\n",
      "Epoch 974/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1045291.4090 - acc: 1.0000e-03 - val_loss: 1045151.5601 - val_acc: 1.0000e-03\n",
      "Epoch 975/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1045021.8810 - acc: 1.0000e-03 - val_loss: 1044880.1463 - val_acc: 1.0000e-03\n",
      "Epoch 976/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1044752.4970 - acc: 1.0000e-03 - val_loss: 1044609.9186 - val_acc: 1.0000e-03\n",
      "Epoch 977/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1044483.7080 - acc: 1.0000e-03 - val_loss: 1044339.6600 - val_acc: 1.0000e-03\n",
      "Epoch 978/1000\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 1044214.3360 - acc: 1.0000e-03 - val_loss: 1044074.9562 - val_acc: 1.0000e-03\n",
      "Epoch 979/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1043946.3775 - acc: 1.0000e-03 - val_loss: 1043803.8079 - val_acc: 1.0000e-03\n",
      "Epoch 980/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1043676.4520 - acc: 1.0000e-03 - val_loss: 1043537.2320 - val_acc: 1.0000e-03\n",
      "Epoch 981/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1043409.0385 - acc: 1.0000e-03 - val_loss: 1043266.7250 - val_acc: 1.0000e-03\n",
      "Epoch 982/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1043142.0015 - acc: 1.0000e-03 - val_loss: 1042996.8575 - val_acc: 1.0000e-03\n",
      "Epoch 983/1000\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 1042874.2630 - acc: 1.0000e-03 - val_loss: 1042732.1535 - val_acc: 1.0000e-03\n",
      "Epoch 984/1000\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 1042606.3500 - acc: 1.0000e-03 - val_loss: 1042466.3280 - val_acc: 1.0000e-03\n",
      "Epoch 985/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1042339.1880 - acc: 1.0000e-03 - val_loss: 1042196.0264 - val_acc: 1.0000e-03\n",
      "Epoch 986/1000\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 1042069.8468 - acc: 1.0000e-03 - val_loss: 1041926.0403 - val_acc: 1.0000e-03\n",
      "Epoch 987/1000\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 1041802.5570 - acc: 1.0000e-03 - val_loss: 1041660.1572 - val_acc: 1.0000e-03\n",
      "Epoch 988/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1041534.9040 - acc: 1.0000e-03 - val_loss: 1041392.8263 - val_acc: 1.0000e-03\n",
      "Epoch 989/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1041265.4825 - acc: 1.0000e-03 - val_loss: 1041124.9604 - val_acc: 1.0000e-03\n",
      "Epoch 990/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1040998.6470 - acc: 1.0000e-03 - val_loss: 1040855.8847 - val_acc: 1.0000e-03\n",
      "Epoch 991/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1040729.7520 - acc: 1.0000e-03 - val_loss: 1040591.4603 - val_acc: 1.0000e-03\n",
      "Epoch 992/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1040461.7690 - acc: 1.0000e-03 - val_loss: 1040321.6685 - val_acc: 1.0000e-03\n",
      "Epoch 993/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1040193.6580 - acc: 1.0000e-03 - val_loss: 1040052.2529 - val_acc: 1.0000e-03\n",
      "Epoch 994/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1039923.8890 - acc: 1.0000e-03 - val_loss: 1039782.5798 - val_acc: 1.0000e-03\n",
      "Epoch 995/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1039655.1000 - acc: 1.0000e-03 - val_loss: 1039513.6703 - val_acc: 1.0000e-03\n",
      "Epoch 996/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1039387.1780 - acc: 1.0000e-03 - val_loss: 1039246.2006 - val_acc: 1.0000e-03\n",
      "Epoch 997/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1039118.8040 - acc: 1.0000e-03 - val_loss: 1038978.9896 - val_acc: 1.0000e-03\n",
      "Epoch 998/1000\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 1038851.1965 - acc: 1.0000e-03 - val_loss: 1038709.3875 - val_acc: 1.0000e-03\n",
      "Epoch 999/1000\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 1038583.6980 - acc: 1.0000e-03 - val_loss: 1038440.2433 - val_acc: 1.0000e-03\n",
      "Epoch 1000/1000\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 1038315.0810 - acc: 1.0000e-03 - val_loss: 1038176.9216 - val_acc: 1.0000e-03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb1b0a5fb70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los datos de validación son los mismos que los de entrenamiento en este caso, porque no tenemos\n",
    "# datos de validación...\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=nEpochs, validation_data=(X_train, Y_train), callbacks=[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cost function over time (epochs)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEICAYAAAB4YQKYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VUX6x/HPE0KRDiEqUgQELNiQCKK0VQRUFFRUdi3sigXsomv56Yqr6yq7qyiugiy6dtYuWACxASoKAaUpSJcIQpRqoT+/P85ErzGQEC65yb3f9+t1Xpw7Z2buzEm4T2bm3HPM3REREdldaYlugIiIJAcFFBERiQsFFBERiQsFFBERiQsFFBERiQsFFBERiQsFFEkoM+tvZivN7HszyyjB9/0/MxtRUu+XKOG8Nimh9+piZq+WxHvt4P07mVlOMcodbmYf7Yk2pRoFFAHAzP5gZtnhA2iFmY0xs3a7WecSM+u8k+PlgfuALu5e1d2/253328n7/OaDxt3/7u4X7Yn3SxQze9/MftWncF4XlVAT/g7cU0LvFTfuPhNYa2anJrotZZ0CimBmA4D7iT4Q9gEaAg8DPfbwW+8DVALm7OH3STpmVi7RbYhlZkcDNdz940S3pZieAS5NdCPKPHfXlsIbUAP4HjhrJ3kqEgWc5WG7H6gYjtUBXgfWAquBSUR/qDwFbAd+CvXfkK/O5sAPgIfj7wKNwuv0mHzvAxeF/T8CHwD/AtYAi4GTYvLWBv4b2rgGeBWoEtqwPbzP98B+wO3A0zFlTyMKbGvDex4cc2wJcD0wE1gHPAdU2sG5SgNuBZYCq4AniT5oAcYCV+TLPwM4I+wfBIwP53EecHZMvseBocCb4bx1zlfPXcA2YGPo479DugNNY+p4GBgT8nwI7Bt+nmuAuUDLmDr3A14CcsO5vmonvyO3ASPypRXWn2Hh+AZgArB/zPFjganhfE8Fjt3ZzzmkdwJygOvCuV8B/Cmm3MnA5+H9vgaujzlWL/yeVEz0/8myvCW8AdoS/AsA3YCtxHyIF5DnDuBjYG8gE/gIuDMcuzt8MJQPW3vAwrEl+T/48tXbiJgAkv91SHufXweULcDFQDmgf/hQyXu/N4g+7GuFtnQM6Z2AnHzvfTshoPBLcDsxlLsBWABUiOnHlPABWxv4Aui3gz5dGMo2AaoCLwNPhWMXAB/G5D2EKIBVJAp8y4A/AenAUcC3QIuQ9/Hw4XocUdD6TUCLPVcxafkDyrdAK6KR4btEgeKCcD7/BrwX8qYB04gCRYXQn0VA1x30+wXgzzGvi9KfDUCH0P8HgA/CsdpEgeL8UPb34XVGEX7OW4l+X8sTBZAfgVrh+AqgfdivBRyVrw/rgcMT/X+yLG+a8pIM4Ft337qTPOcCd7j7KnfPBf5K9J8dog/4ukR/XW5x90ke/nfuIUvd/T/uvg14Irz3PmZWFziJ6IN+TWjLhCLWeQ7whruPd/ctRCOgvYj+Ss4zxN2Xu/tq4DXgyB3UdS5wn7svcvfvgZuB3maWDrwCHGlm+8fkfdndNwHdgSXu/l933+ru04lGB71i6h7l7h+6+3Z331jEvuX3irtPC+VfATa6+5PhfD4HtAz5jgYy3f0Od9/s0TrMf4DeO6i3JlGAyFOU/rzh7hND/28B2ppZA+AUYL67PxXKjiQaPZ1ahJ/zFqLf1S3u/ibRSOzAmGOHmFn1UHZ6vj5sCP2QYlJAke+AOuEDb0f2I5rCybM0pAH8k+gv8rfMbJGZ3bRnmvmzb/J23P3HsFsVaACsdvc1xajzV/1z9+1Ef13XK+h9if7qrVqUusJ+OrCPu28g+us670O5N9HcPcD+QBszW5u3EQWcfWPqWrYrndqBlTH7PxXwOq9f+wP75WvP/xGtexVkDVAt5vUu9ScE39VE5y//OSS8rkfhP+fv8v1xFPuzOpNo1LLUzCaYWdt8ZasRjRilmBRQZDLRvHvPneRZTvQBkadhSMPdN7j7de7eBDgVGGBmJ4R8uzpS+SH8Wzkmbd+CMhZgGVDbzAr6C7Owdvyqf2ZmRB9cXxfxvXdYF9G52sovH9wjgd+HD7O9gPdC+jJggrvXjNmqunv/XehHPEeGy4DF+dpTzd1P3kH+mURTh7HlC+tPg7wdM6tKNNWVt04Xew4hOo9fs/Of8065+1R370E0dfsq8HzM++9HNLU3b1frlV8ooKQ4d19HNE/+kJn1NLPKZlbezE4ys3+EbCOBW80s08zqhPxPA5hZdzNrGj6E1xMtDG8L5VYSzb0XtS25RB8a55lZOTO7EDigiGVXEC02P2xmtUIfOsS0I8PMauyg+PPAKWZ2QriU+TpgE9Fa0a4aCVxrZo3Dh+Tfgedi/mp+k+jD8o6Qvj2kvw40N7PzQ9vLm9nRZnbwLrz3Lp3vQkwB1pvZjWa2V/h5HBqu5irIm0DHmNdF6c/JZtbOzCoAdwKfuPuyUFfzcCl7upmdQ7Te9HohP+cdMrMKZnaumdUI05p5v6t5OgHvhuk3KSYFFMHd7wMGEF2dlEv0V+AVRH/FQbRYm030V+gsYHpIA2gGvE00Vz0ZeNjd3w/H7iYKRGvN7PoiNudi4M9EU3Et2LUP9fOJ5snnEl3lc03o31yiD/pFoS37xRZy93nAecCDRAvHpwKnuvvmXXjvPI8RXeE2kWjBeyNwZcx7bSJaqO8MPBuTvgHoQjQNtpxoim0Q0YJ1UT0A9DKzNWY2pBht/1lYUzmVaK1oMdF5GUF0VWBB+acD68ysTXhdlP48CwwkmupqRTQlhkffR+pOFNi/I7pIoru7fxvKFfhzLoLzgSVmth7oR/Qzz3Mu0cUlshvyro4REdktZtYFuMzddzZ9mpf3caIr727d4w0rvC2HAcPdPf+aiuyinS3EiogUmbu/BbyV6HbsKnefBSiYxIGmvEREJC405SUiInGhEYqIiMRFSq2h1KlTxxs1apToZoiIlCnTpk371t0zC8uXUgGlUaNGZGdnJ7oZIiJlipnlv3NBgTTlJSIicaGAIiIicaGAIiIicaGAIiIicaGAIiIicaGAIiIicaGAIiIicaGAUgRvzFzBqM+K86wlEZHUkVJfbCwOd+fFact4b14um7Zs5+yjGxReSEQkBWmEUggzY/gFWRx7QAY3vDSTW16ZxcYt2wovKCKSYhRQiqB8uTQe/1NrLu3QhGc++YqeD33IglUbEt0sEZFSRQGliCqkp3HzyQfz+J+OJnfDJk598EPGzFqR6GaJiJQaCii7qNOBe/Pm1e1pvm81+j8znT+/MIMNG7ckulkiIgmngFIM+1SvxAuXtuWK3zXlpek5nPTAJKYsXp3oZomIJJQCSjFVSE/j+q4H8kK/tqSZcc7wydwzZi6btmrBXkRSkwLKbmq1f23GXN2e3kc3YNiEhfR86CPmfaMFexFJPQoocVClYjp3n3E4j/bJInfDRk598AP+M3ER27d7opsmIlJiFFDi6ISD92HcNR3oeGAmd735BX8Y8TFfr/0p0c0SESkRCihxllG1IsPPb8U/zjycWTnr6DZ4Ii9Pz8FdoxURSW4KKHuAmXH20Q0Ye00HDqpbjQHPz+DyZ6ez5ofNiW6aiMgeo4CyBzWoXZn/XdKWG7sdxPjPV9L1/om8P29VopslIrJHKKDsYeXSjP6dDuDVy4+jZuXy/PG/U/nLq7P5cfPWRDdNRCSuFFBKSIv9ajD6inZc1K4xT328lO5DPuCzZWsT3SwRkbhRQClBlcqX49buh/DsRW3YuGUbZw79iPvf/pIt27YnumkiIrtNASUBjm1ahzHXdOC0I/bj/rfn02vYZBblfp/oZomI7BYFlASpsVd5Bp9zJA/94SiWfvcDJw+ZxFOTl+jyYhEpswoNKGb2mJmtMrPZMWl3mtlMM/vMzN4ys/1ijt1sZgvMbJ6ZdY1Jb2Vms8KxIWZmIb2imT0X0j8xs0YxZfqY2fyw9YlJbxzyzg9lK+z+qUiMUw6vy7hrOtC6cQZ/GTWHP/53KqvWb0x0s0REdllRRiiPA93ypf3T3Q939yOB14HbAMzsEKA30CKUedjMyoUyQ4FLgGZhy6uzL7DG3ZsCg4FBoa7awECgDdAaGGhmtUKZQcBgd28GrAl1lFn7VK/EE386mjt7tOCTxd/R5f6JvKlnrYhIGVNoQHH3icDqfGnrY15WAfLmaXoA/3P3Te6+GFgAtDazukB1d5/s0ZzOk0DPmDJPhP0XgRPC6KUrMN7dV7v7GmA80C0cOz7kJZTNq6vMMjPOb9uIN65qz/61K3PZM9MZ8NxnrNezVkSkjCj2GoqZ3WVmy4BzCSMUoB6wLCZbTkirF/bzp/+qjLtvBdYBGTupKwNYG/Lmr6ugdl5iZtlmlp2bm7ur3SxxB2RW5cX+x3L1Cc0YNWM5J90/ickLv0t0s0REClXsgOLut7h7A+AZ4IqQbAVl3Ul6ccrsrK6C2jnc3bPcPSszM3NH2UqV8uXSuPbE5rzYry0V0tP4w4iPueuNz9m4Rc9aEZHSKx5XeT0LnBn2c4AGMcfqA8tDev0C0n9VxszSgRpEU2w7qutboGbIm7+upNKyYS3euKod57ZpyH8mLabHvz/k8+XrCy8oIpIAxQooZtYs5uVpwNywPxroHa7caky0+D7F3VcAG8zsmLAGcgEwKqZM3hVcvYB3wzrLOKCLmdUKi/FdgHHh2HshL6FsXl1Jp3KFdP7W8zD++6ejWf3jZno89AHDJixkm561IiKlTFEuGx4JTAYONLMcM+sL3GNms81sJtEH/dUA7j4HeB74HBgLXO7uefM0/YERRAv1C4ExIf1RIMPMFgADgJtCXauBO4GpYbsjpAHcCAwIZTJCHUntdwfuzbhrOtD54H24Z8xcfj/8Y5at/jHRzRIR+Zml0hfpsrKyPDs7O9HN2C3uziuffs3AUXPY7s7A01pwVqv6hK/1iIjEnZlNc/eswvLpm/JljJlxxlH1GXNNew6tV4MbXpxJv6en8d33mxLdNBFJcQooZVT9WpUZefEx3HLywbw3N5eu90/inS9WJrpZIpLCFFDKsLQ04+IOTRh95XHUqVqBvk9kc9NLM/l+k561IiIlTwElCRy0b3VGXXEc/ToewPPZy+h2/0R9GVJESpwCSpKomF6Om046iBf6tSU9zfj9fz7mjtf0ZUgRKTkKKEmm1f61efPq9lzQdn8e+3AxpwyZxAw9GVJESoACShKqXCGdO3ocytN92/DT5m2cMfQj7n1rHpu36smQIrLnKKAksXbN6jD22g70PLIeD767gNMf/pB532xIdLNEJEkpoCS56pXKc+/ZRzD8/FasXL+RUx/UrVtEZM9QQEkRXVrsy7hrOnDCwXtzz5i5nP3IZJZ8+0OimyUiSUQBJYVkVK3Iw+cexf3nHMn8lRs46YFJPDl5Cds1WhGROFBASTFmRs+W9Xjr2o4c3bg2t42awwWPTWH52p8S3TQRKeMUUFLUvjWi59j//fTDmP7VGrreP5GXpuWQSjcLFZH4UkBJYWbGH9o0ZOzVHTh43+pc98IMLn1qGt/qRpMiUgwKKELDjMqMvCS60eT7X+bSZfBExs5ekehmiUgZo4AiAJQLN5p848p21Ku5F/2ens61z33Guh+3JLppIlJGKKDIrzTbpxovX3Ys13RuxmszltP1/olM+DI30c0SkTJAAUV+o3y5NK7p3JxXLjuOapXS6fPYFG55ZRY/6Lb4IrITCiiyQ4fVr8FrV7bjkg5NeHbKV5z0wCSmLF6d6GaJSCmlgCI7Val8Of7v5IN57pK2AJwzfDJ/f/ML3RZfRH5DAUWKpHXj2oy5uj1/aN2Q4RMX0f3BD/hMt8UXkRgKKFJkVSqmc9fph/Hkha35YdNWznj4QwaNnavRiogACihSDB2aZzLu2g6cndWAoe8v5FSNVkQEBRQppuqVynPPmYfzxIWt+T6MVu4Zo9GKSCorNKCY2WNmtsrMZsek/dPM5prZTDN7xcxqhvRGZvaTmX0WtmExZVqZ2SwzW2BmQ8zMQnpFM3supH9iZo1iyvQxs/lh6xOT3jjknR/KVojP6ZBd1TFmtDJswkKtrYiksKKMUB4HuuVLGw8c6u6HA18CN8ccW+juR4atX0z6UOASoFnY8ursC6xx96bAYGAQgJnVBgYCbYDWwEAzqxXKDAIGu3szYE2oQxIkb7Ty5IWt+VGjFZGUVWhAcfeJwOp8aW+5e9633D4G6u+sDjOrC1R398ke3c72SaBnONwDeCLsvwicEEYvXYHx7r7a3dcQBbFu4djxIS+hbF5dkkAdmmcyNt9o5dOv1iS6WSJSQuKxhnIhMCbmdWMz+9TMJphZ+5BWD8iJyZMT0vKOLQMIQWodkBGbnq9MBrA2JqDF1iUJln+0cubQj7h7jL63IpIKdiugmNktwFbgmZC0Amjo7i2BAcCzZlYdsAKK5z14Y0fHdjV9R228xMyyzSw7N1f3pCopsaOVRyYs0mhFJAUUO6CERfLuwLlhGgt33+Tu34X9acBCoDnRKCJ2Wqw+sDzs5wANQp3pQA2iKbaf0/OV+RaoGfLmr+s33H24u2e5e1ZmZmZxuyvFoNGKSGopVkAxs27AjcBp7v5jTHqmmZUL+02IFt8XufsKYIOZHRPWQC4ARoVio4G8K7h6Ae+GADUO6GJmtcJifBdgXDj2XshLKJtXl5RCed9bOefoaLRyypBJGq2IJKGiXDY8EpgMHGhmOWbWF/g3UA0Yn+/y4A7ATDObQbRo3s/d8xb0+wMjgAVEI5e8dZdHgQwzW0A0TXYTQCh3JzA1bHfE1HUjMCCUyQh1SClWrVJ57j4jGq38tHmbRisiSchS6RniWVlZnp2dnehmpLwNG7fw9ze/YOSUZRyQWYV/nXUELRvWKrygiCSEmU1z96zC8umb8lLiNFoRSU4KKJIwv6ytNPx5bWW61lZEyiwFFEmoaLRyGE/1jUYrvYZ+xN163opImaSAIqVC+2Yxo5WJGq2IlEUKKFJqaLQiUrYpoEipo9GKSNmkgCKlUkGjFT3LXqR0U0CRUi12tDJ84iJO1mhFpNRSQJFSL2+08nTfNmzasl2jFZFSSgFFyox2zeow9pr2vxqtTFuq0YpIaaGAImVK/tHKWcM0WhEpLRRQpEzSaEWk9FFAkTJLoxWR0kUBRcq8ds3qMO7aDvRurdGKSCIpoEhSqFoxnb+fHnMl2LCPuOuNzzVaESlBCiiSVPJGK79v3ZD/TFrMyQ9MYtrS1YUXFJHdpoAiSedXo5Wt2+k1bLJGKyIlQAFFkpZGKyIlSwFFklpBo5W/va7RisieoIAiKSFvtPKH1g0Z8YFGKyJ7ggKKpIyqFdO56/TDeOYijVZE9gQFFEk5xzX97Wgle4lGKyK7SwFFUlL+0cpZj0SjlZ82a7QiUlwKKJLSfjNaGaLRikhxKaBIyosdrWzWaEWk2AoNKGb2mJmtMrPZMWn/NLO5ZjbTzF4xs5oxx242swVmNs/MusaktzKzWeHYEDOzkF7RzJ4L6Z+YWaOYMn3MbH7Y+sSkNw5554eyFXb/VEiq02hFZPcUZYTyONAtX9p44FB3Pxz4ErgZwMwOAXoDLUKZh82sXCgzFLgEaBa2vDr7AmvcvSkwGBgU6qoNDATaAK2BgWZWK5QZBAx292bAmlCHyG4raLRyp0YrIkVSaEBx94nA6nxpb7n71vDyY6B+2O8B/M/dN7n7YmAB0NrM6gLV3X2yuzvwJNAzpswTYf9F4IQweukKjHf31e6+hiiIdQvHjg95CWXz6hKJi9jRyqMarYgUSTzWUC4ExoT9esCymGM5Ia1e2M+f/qsyIUitAzJ2UlcGsDYmoMXW9RtmdomZZZtZdm5u7i53TlJXQaOV20fP4YdNWwsvLJKCdiugmNktwFbgmbykArL5TtKLU2Zndf32gPtwd89y96zMzMwdZRPZobzRygXH7M/jHy2hy+CJTPxSf5yI5FfsgBIWybsD54ZpLIhGCw1istUHlof0+gWk/6qMmaUDNYim2HZU17dAzZA3f10ie0TViun8tcehvNCvLRXLp3HBY1O4/oUZrPtxS6KbJlJqFCugmFk34EbgNHf/MebQaKB3uHKrMdHi+xR3XwFsMLNjwhrIBcComDJ5V3D1At4NAWoc0MXMaoXF+C7AuHDsvZCXUDavLpE96uhGtXnzqvZc1ukAXvn0azoPnsDY2SsS3SyRUqEolw2PBCYDB5pZjpn1Bf4NVAPGm9lnZjYMwN3nAM8DnwNjgcvdPe/ymP7ACKKF+oX8su7yKJBhZguAAcBNoa7VwJ3A1LDdEdIgCmYDQpmMUIdIiahUvhw3dDuIUZcfR2bVivR7ejr9n57Gqg0bE900kYSyX2arkl9WVpZnZ2cnuhmSRLZs287wiYt44J357FW+HLd1P4QzjqpH+JqVSFIws2nunlVYPn1TXmQ3lC+XxuW/a8qbV7Wn6d5Vue6FGfT571Ry1vxYeGGRJKOAIhIHTfeuyguXtuWvp7Uge8lqug6eyJOTl7B9e+rMAIgooIjESVqa0efYRoy7pgNH7V+L20bN4Zzhk1mY+32imyZSIhRQROKsQe3KPHlha/7Z63DmfbOBkx6YxMPvL2Drtu2JbprIHqWAIrIHmBlnZTXg7es6cvyBe/OPsfPo+fCHzFm+LtFNE9ljFFBE9qC9q1Vi2PmtGHruUXyzbhOn/ftD/jlurh47LElJAUWkBJx0WF3eHtCBnkfW46H3FnLKkElMW6qbTUpyUUARKSE1K1fg3rOP4IkLW7Nxy3Z6DdPNJiW5KKCIlLCOzTN/vtnkE5Ojm01Omq+bTUrZp4AikgB5N5t8/tLoZpPnPzqFP+tmk1LGKaCIJFDszSZf/vlmk98kulkixaKAIpJgv73Z5DQue0Y3m5SyRwFFpJQ4tF4NRl1xHH/ueiBvf7GKE++byEvTckilG7hK2aaAIlKKxN5sspluNilljAKKSCnUdO+qPK+bTUoZo4AiUkrl3WzyrWt/udnkWY9MZv7KDYlumkiBFFBESrn6taKbTd539hEsyv2ek4dM4r7xX7Jpq27fIqWLAopIGWBmnHFUfd4e0JFTDqvLkHfmc/IDk5i6RLdvkdJDAUWkDMmoWpH7e7f8+fYtZw2bzC2vzGL9Rn0hUhJPAUWkDOrYPJPxAzpwUbvGjJzyFSfepy9ESuIpoIiUUZUrpHNr90N49fLjqF0l+kLkpU9ls3K9vhApiaGAIlLGHV6/JqOvOI4bux3E+/Ny6XzvBJ75ZKkuMZYSp4AikgTKl0ujf6cDGHdNBw6rX4NbXplN7+Efs2CVnmcvJUcBRSSJNKpThWcuasM/eh3OvJUbOPmBSQx5Zz6bt+p59rLnKaCIJBkz4+ysBrw9oCNdD92X+8Z/SfcHJzFt6ZpEN02SXKEBxcweM7NVZjY7Ju0sM5tjZtvNLCsmvZGZ/WRmn4VtWMyxVmY2y8wWmNkQM7OQXtHMngvpn5hZo5gyfcxsftj6xKQ3Dnnnh7IVdv9UiCSXzGoVefD3LXnsj1l8v3ErvYZ9xG2jZrNBlxjLHlKUEcrjQLd8abOBM4CJBeRf6O5Hhq1fTPpQ4BKgWdjy6uwLrHH3psBgYBCAmdUGBgJtgNbAQDOrFcoMAga7ezNgTahDRApw/EH78NaAjvRp24inPl7KifdNZPznKxPdLElChQYUd58IrM6X9oW7zyvqm5hZXaC6u0/26F7cTwI9w+EewBNh/0XghDB66QqMd/fV7r4GGA90C8eOD3kJZfPqEpECVK2Yzu2nteDl/sdSY6/yXPxkNpc/M13PXJG42hNrKI3N7FMzm2Bm7UNaPSAnJk9OSMs7tgzA3bcC64CM2PR8ZTKAtSFv/rp+w8wuMbNsM8vOzdVzuyW1tWxYi9eubMf1XZoz/ouVdL53Av+b8pWeuSJxEe+AsgJo6O4tgQHAs2ZWHbAC8ub9Bu/o2K6mF8jdh7t7lrtnZWZm7rTxIqmgQnoaVxzfjLFXt+fgutW56eVZ9B7+MYtydYmx7J64BhR33+Tu34X9acBCoDnRKKJ+TNb6wPKwnwM0ADCzdKAG0RTbz+n5ynwL1Ax589clIkXUJLMqIy8+hrvPOIzPV6yn2wOTeOi9BWzZpkuMpXjiGlDMLNPMyoX9JkSL74vcfQWwwcyOCWsgFwCjQrHRQN4VXL2Ad8M6yzigi5nVCovxXYBx4dh7IS+hbF5dIrIL0tKM37duyDsDOtL54L3557h5nPrgB3z6lS4xll1XlMuGRwKTgQPNLMfM+prZ6WaWA7QF3jCzcSF7B2Cmmc0gWjTv5+55C/r9gRHAAqKRy5iQ/iiQYWYLiKbJbgII5e4Epobtjpi6bgQGhDIZoQ4RKaa9q1fi4XNb8Z8Lslj74xbOGPoRf31tDj9s2lp4YZHAUmkxLisry7OzsxPdDJFSbcPGLfxj7Dye/mQp+9XYi7/1PJTfHbR3opslCWRm09w9q7B8+qa8iPxKtUrlubPnobzYry2VK5TjT49P5cqRn/Lt95sS3TQp5RRQRKRArfavzetXtePazs0ZN/sbTrh3As9nL9MlxrJDCigiskMV08txdedmvHl1O5rtXZUbXpzJeY9+wpJvf0h006QUUkARkUI13bsaz1/alr/1PJSZy9bR9f6JPPTeAt3FWH5FAUVEiiQtzTjvmP0ZP6Ajxx/0yyXG05auLrywpAQFFBHZJfvWqMTQ81ox4oIsNmzcwplDJ3PLK7NY95PuYpzqFFBEpFg6H7IP4wd0pG+7xoyc8hUn3DuB12Ys16J9ClNAEZFiq1Ixnb90P4TRV7Sjbo1KXDnyU/70+FSWrf4x0U2TBFBAEZHddmi9Grxy2bHc1v0Qpi5ezYmDJzBswkLdFyzFKKCISFykl0vjwnaNGT+gI+2aZnLPmLm6L1iKUUARkbjar+ZejOiTxSPnt/r5vmC3jZrNej16OOkpoIjIHtG1xb6MH9Ah5tHDExgza4UW7ZOYAoqI7DHVKpXn9tNa8Oplx5FRpSL9n5nORU9k8/XanxLdNNkDFFBEZI87okFNRl9xHLeecjAfLfyOE++bwIhJi9iqRfukooAiIiUivVwaF7VvwvgBHTimSQZ/e+MLejz0ITNz1ia6aRIX9MOaAAAPp0lEQVQnCigiUqLq16rMo32yGHruUeRu2ETPhz7k9tFz+F4P8yrzFFBEpMSZGScdVpe3r+vIuW3254nJS+h87wTGzfkm0U2T3aCAIiIJUz08zOul/sdSs3J5Ln1qGhc/mc1yLdqXSQooIpJwRzWsxWtXtuOmkw5i0vxcTrxvAo99sJht23WJcVmigCIipUL5cmn063gA46/tSFaj2tzx+uf0fOhDZn+9LtFNkyJSQBGRUqVB7co8/qejefD3LVmxbiOn/fsD/vb65/ygRftSTwFFREodM+PUI/bjnes60rt1Q0Z8sJjO901g7Oxv9E37UkwBRURKrRp7lefvpx/GS/2PpcZe5en39DQueiJbt8cvpRRQRKTUa7V/tGh/y8kHM3nRd5w4eAJD31+oZ9qXMgooIlImlC+XxsUdmvD2gI50bJ7JoLFzOWXIJKYs1jPtS4tCA4qZPWZmq8xsdkzaWWY2x8y2m1lWvvw3m9kCM5tnZl1j0luZ2axwbIiZWUivaGbPhfRPzKxRTJk+ZjY/bH1i0huHvPND2Qq7dxpEpKzYr+ZePHJ+FiMuyOLHzds4+5HJ/PmFGaz+YXOim5byijJCeRzoli9tNnAGMDE20cwOAXoDLUKZh82sXDg8FLgEaBa2vDr7AmvcvSkwGBgU6qoNDATaAK2BgWZWK5QZBAx292bAmlCHiKSQ6Jn2Hejf6QBe+fRrjr/3fZ6b+hXb9d2VhCk0oLj7RGB1vrQv3H1eAdl7AP9z903uvhhYALQ2s7pAdXef7NElGk8CPWPKPBH2XwROCKOXrsB4d1/t7muA8UC3cOz4kJdQNq8uEUkhlSukc2O3g3jz6vY037saN740i7Mfmczcb9YnumkpKd5rKPWAZTGvc0JavbCfP/1XZdx9K7AOyNhJXRnA2pA3f12/YWaXmFm2mWXn5uYWs1siUpo136caz116DP/sdTgLc7+n+5APuHvMF/y4Wd9dKUnxDihWQJrvJL04ZXZW128PuA939yx3z8rMzNxRNhEp48yMs7Ia8O51nTjzqPo8MmERJ943kfGfr0x001JGvANKDtAg5nV9YHlIr19A+q/KmFk6UINoim1HdX0L1Ax589clIimuVpUKDOp1OC/0a0uViuW4+MlsLn5ST4ksCfEOKKOB3uHKrcZEi+9T3H0FsMHMjglrIBcAo2LK5F3B1Qt4N6yzjAO6mFmtsBjfBRgXjr0X8hLK5tUlIgLA0Y1q88ZV7bn5pIP4YP63dL53Ao9MWMgWPSVyjynKZcMjgcnAgWaWY2Z9zex0M8sB2gJvmNk4AHefAzwPfA6MBS53922hqv7ACKKF+oXAmJD+KJBhZguAAcBNoa7VwJ3A1LDdEdIAbgQGhDIZoQ4RkV8pXy6NSzsewPgBHTiuaR3uHjOX7kM+IHuJvruyJ1gq3RcnKyvLs7OzE90MEUmQt+Z8w+2j57B83UbOyWrATScdRK0q+hpbYcxsmrtnFZZP35QXkZTRpcW+jB/QkUs7NOHF6Tkcf+/7vJC9TDecjBMFFBFJKVUqpnPzyQfzxlXtaJJZlT+/OJNzHvmYL1duSHTTyjwFFBFJSQftW50XLm3LoDMP48tVGzj5gUkMGjuXnzZvK7ywFEgBRURSVlqacc7RDXlnQEd6tqzH0PcXcuLgCbw7V99dKQ4FFBFJeRlVK/Kvs47guUuOYa/y5bjw8WwufSqb5fruyi5RQBERCdo0yeCNq9pzQ7cDmfBlLp3vm8CISYvYqu+uFIkCiohIjArpaVzWqSnjr+3IMU0y+NsbX9D9wQ+Yqu+uFEoBRUSkAA1qV+bRPlkMO68V63/awlnDJnPd8zPI3bAp0U0rtRRQRER2wMzodui+vH1dRy7rdACjZ0TPXXnioyWaBiuAAoqISCEqV0jnhm4HMfaaDhxRvyYDR8/htH9/yLSlaxLdtFJFAUVEpIgOyKzKU31b89AfjmL1D5s5c+hH3PDiDL77XtNgoIAiIrJLzIxTDq/LO9dFt3B5efrX/O5f7/PUx0vZluKPH1ZAEREphrxbuIy5uj0t9qvBX16dTc+HPuSzZWsT3bSEUUAREdkNzfapxrMXt+GB3keycv1GTn/4Q25+eSZrftic6KaVOAUUEZHdZGb0OLIe71zXkb7HNeb57Bx+d+/7jJzyFdtTaBpMAUVEJE6qVSrPrd0P4c2r2tN8n2rc/PIsTh/6EbNy1iW6aSVCAUVEJM4O3Lcaz11yDIPPOYKv1/zEaQ99wK2vzmLtj8k9DaaAIiKyB5gZp7esz7vXd6RP20Y8+8lXHH/vBJ6fuixpp8EUUERE9qDqlcpz+2kteP3K9jSuU4UbXppJr2EfMfvr5JsGU0ARESkBh+wXPdDrX2cdwdLvfuS0f3/AwFGzWffTlkQ3LW4UUERESkhamtGrVX3eva4T5x2zP099vJQT7n2fl6blJMVz7RVQRERKWI3K5bmjx6GMvqId9WtV5roXZnD2I5P5YsX6RDdttyigiIgkyKH1avBy/2MZdOZhLFj1Pd0f/IA7Xvuc9RvL5jSYAoqISALlPdf+ves70fvoBvz3o8WccO8EXv306zI3DaaAIiJSCtSsXIG7Tj+MVy87jro1KnHNc59xzvCPmffNhkQ3rcgKDShm9piZrTKz2TFptc1svJnND//WCumNzOwnM/ssbMNiyrQys1lmtsDMhpiZhfSKZvZcSP/EzBrFlOkT3mO+mfWJSW8c8s4PZSvE53SIiCTWEQ1q8splx3HX6Ycy75sNnDxkEne98Tnfb9qa6KYVqigjlMeBbvnSbgLecfdmwDvhdZ6F7n5k2PrFpA8FLgGahS2vzr7AGndvCgwGBkEUtICBQBugNTAwL3CFPIPD+68JdYiIJIVyaca5bfbnves7cVar+vxn0mJOuPd9XpuxvFRPgxUaUNx9IrA6X3IP4Imw/wTQc2d1mFldoLq7T/bobDwZUya2rheBE8LopSsw3t1Xu/saYDzQLRw7PuQt0vuLiJRFtatU4J4zD+fly44ls1pFrhz5KeeO+IQFq0rnNFhx11D2cfcVAOHfvWOONTazT81sgpm1D2n1gJyYPDkhLe/YslDXVmAdkBGbnq9MBrA25M1f12+Y2SVmlm1m2bm5ubveUxGRBDuqYS1GXd6OO3u0YPbX6+h2/yTuHvMFP5SyabB4L8qvABq6e0tgAPCsmVUHrIC8eeO2HR3b1fQCuftwd89y96zMzMydNl5EpLQql2ac37YR717fiZ4t6/HIhEV0vm8Cb85aUWqmwYobUFaGaay86axVAO6+yd2/C/vTgIVAc6JRRP2Y8vWB5WE/B2gQ6koHahBNsf2cnq/Mt0DNkDd/XSIiSa1O1Yr866wjeLFfW2pWrsBlz0zngsemsCj3+0Q3rdgBZTSQd9VVH2AUgJllmlm5sN+EaPF9UZgW22Bmx4Q1kAvyyuSrqxfwblhnGQd0MbNaYTG+CzAuHHsv5P3V+4uIpIqsRrV57YrjuP3UQ/jsq7V0vX8i/xw3lx83J24azAobKpnZSKATUAdYSXTl1avA80BD4CvgLHdfbWZnAncAW4FtwEB3fy3Uk0V0xdhewBjgSnd3M6sEPAW0JBqZ9Hb3RaHMhcD/habc5e7/DelNgP8BtYFPgfPcfVNhnc3KyvLs7OzCz4qISBmyasNG7nlzLi9/+jX1au7FX7ofQtcW+xC+nbHbzGyau2cVmq+0zL2VBAUUEUlmnyz6jttGzWHeyg10OjCT209tQaM6VXa73qIGFH1TXkQkSbRpksHrV7Xj1lMOJnvJGroMnsh9b81j45ZtJfL+CigiIkmkfLk0LmrfhHeu68hJh+3LkHcX0Pm+CSVyCxcFFBGRJLRP9Uo80Lslz17chsZ1qlC/1l57/D3TC88iIiJl1bEH1OHYA+qUyHtphCIiInGhgCIiInGhgCIiInGhgCIiInGhgCIiInGhgCIiInGhgCIiInGhgCIiInGRUjeHNLNcYGkxi9chehZLKlGfU0Oq9TnV+gu73+f93b3QJxSmVEDZHWaWXZS7bSYT9Tk1pFqfU62/UHJ91pSXiIjEhQKKiIjEhQJK0Q1PdAMSQH1ODanW51TrL5RQn7WGIiIicaERioiIxIUCioiIxIUCSiHMrJuZzTOzBWZ2U6LbEy9m1sDM3jOzL8xsjpldHdJrm9l4M5sf/q0VU+bmcB7mmVnXxLW++MysnJl9amavh9dJ3V8AM6tpZi+a2dzw826b7P02s2vD7/VsMxtpZpWSrc9m9piZrTKz2TFpu9xHM2tlZrPCsSFmZsVulLtr28EGlAMWAk2ACsAM4JBEtytOfasLHBX2qwFfAocA/wBuCuk3AYPC/iGh/xWBxuG8lEt0P4rR7wHAs8Dr4XVS9zf05QngorBfAaiZzP0G6gGLgb3C6+eBPyZbn4EOwFHA7Ji0Xe4jMAVoCxgwBjipuG3SCGXnWgML3H2Ru28G/gf0SHCb4sLdV7j79LC/AfiC6D9iD6IPIMK/PcN+D+B/7r7J3RcDC4jOT5lhZvWBU4ARMclJ218AM6tO9MHzKIC7b3b3tSR5v4keb76XmaUDlYHlJFmf3X0isDpf8i710czqAtXdfbJH0eXJmDK7TAFl5+oBy2Je54S0pGJmjYCWwCfAPu6+AqKgA+wdsiXDubgfuAHYHpOWzP2FaHSdC/w3TPWNMLMqJHG/3f1r4F/AV8AKYJ27v0US9znGrvaxXtjPn14sCig7V9BcYlJdZ21mVYGXgGvcff3OshaQVmbOhZl1B1a5+7SiFikgrcz0N0Y60bTIUHdvCfxANBWyI2W+32HdoAfR1M5+QBUzO29nRQpIK1N9LoId9TGufVdA2bkcoEHM6/pEQ+ekYGbliYLJM+7+ckheGYbBhH9XhfSyfi6OA04zsyVEU5fHm9nTJG9/8+QAOe7+SXj9IlGASeZ+dwYWu3uuu28BXgaOJbn7nGdX+5gT9vOnF4sCys5NBZqZWWMzqwD0BkYnuE1xEa7keBT4wt3vizk0GugT9vsAo2LSe5tZRTNrDDQjWswrE9z9Znev7+6NiH6O77r7eSRpf/O4+zfAMjM7MCSdAHxOcvf7K+AYM6scfs9PIFojTOY+59mlPoZpsQ1mdkw4VxfElNl1ib5SobRvwMlEV0AtBG5JdHvi2K92REPbmcBnYTsZyADeAeaHf2vHlLklnId57MaVIInegE78cpVXKvT3SCA7/KxfBWole7+BvwJzgdnAU0RXNyVVn4GRRGtEW4hGGn2L00cgK5ynhcC/CXdQKc6mW6+IiEhcaMpLRETiQgFFRETiQgFFRETiQgFFRETiQgFFRETiQgFFRETiQgFFRETi4v8BJQLI73H9MCIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Echemos un vistazo al coste en función de la época\n",
    "\n",
    "x = range(1,len(l.losses)+1)\n",
    "y = l.losses\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Cost function over time (epochs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.409994]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A ver qué tal ha aprendido a predecir la secuencia\n",
    "\n",
    "TryValue = 10\n",
    "\n",
    "# debería precedir un valor cercano a TryValue * 2\n",
    "model.predict(X_train[TryValue:TryValue+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb1a81ba898>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl81NXZ9/HPlYVA2JeAbCGAgOwIYdPWSrHWai3WFVdQaLR1qT5al9rnsbetrdUu6l1tpYIiKmtRaW3dqMvtwhII+xoWIRCSsCYQss71/JFp75SCQCaTSWa+79crr5k585vMdbJ8c3J+yzF3R0REoldcpAsQEZHwUtCLiEQ5Bb2ISJRT0IuIRDkFvYhIlFPQi4hEOQW9iEiUU9CLiEQ5Bb2ISJRLiHQBAO3atfO0tLRIlyEi0qAsW7Zsr7unnGy7ehH0aWlpZGZmRroMEZEGxcy+OJXtNHUjIhLlFPQiIlFOQS8iEuVOGvRmNs3M8s1szTHtd5rZRjNba2ZPVGt/yMyyg899MxxFi4jIqTuVnbEvAb8HXv5ng5mNAcYBg9y91MzaB9v7AeOB/kAn4H0z6+3ulbVduIiInJqTjujd/WNg/zHN3wced/fS4Db5wfZxwCx3L3X3bUA2MKIW6xURkdNU0zn63sBXzWyxmX1kZsOD7Z2BndW2ywm2iYhIhNT0OPoEoDUwChgOzDGzHoAdZ9vjrlVoZhlABkBqamoNyxARCb/KgFNSXklpRYDSikpKywOUVgQoqwhQVlnVXl7plFcEqAgEKKt0KioDVFQ6FQGnIlB1vzLgVHrVbUVl1f3eHZrx7UGdwlp/TYM+B5jvVQvOLjGzANAu2N612nZdgN3H+wTuPgWYApCenq6Fa0UkLCoqAxwoLmffkVIOHCnnYHEZB4+WU3i0nMKScgqPVnC4tIKikgoOl5ZTXFbJkdIKissqKS6r5Gh5JWUVgbDV9+1BHett0L8BfB340Mx6A42AvcAC4DUz+y1VO2N7AUtqo1ARkWOVVlSSc+AoO/cXk3uohN0Hj5J7qIS8whIKikrJLyrlQHEZfoKhZHyc0bxxAi0aJ9IsKYFmSQm0bdqIrm2SSU6MJ7lRPE0aJdAkMZ6kxDgaJ8TRODGeRglxJCXEk5QQR2JCHI3i42iUYCTGxwU/jIS4OBLiq9ri44yEOCM++JEQV9UWZ2B2vImQ2nXSoDezmcD5QDszywEeAaYB04KHXJYBE4Kj+7VmNgdYB1QAt+uIGxEJ1f4jZWzILWRTXhFbCo6wpeAw2/ceIbew5N9CPM6gffPGdGjZmK5tkhnWrTXtmiXRtlkj2jRtRJvkRrRKbkSr5ERaJSfSJDG+ToI20sxP9KeuDqWnp7uudSMiUBXqK3YeYOXOQ6zMOci63YXkF5X+6/nmjRPomdKMHu2akto2mdQ2yXRtk0ynVk3o0DyJhPjYOQ/UzJa5e/rJtqsXFzUTkdi193Apn2bvZdHW/Szdvp/s/MMAmEHv9s35Sq929OvYgrPOaEHvDs1IaZ4UE6Pw2qSgF5E65e6syjnEu+v28NGmAtbsKgSgeVICw9Jac/nQzgxNbc3Azi1pmqSIqg36KopI2Lk7WTsPsmDFbt5Zu4fcQyXExxnDUltz7zd6c17vFAZ0bkl8nEbq4aCgF5Gw2X3wKHMyd/JG1i627ysmKSGO83qncN+FfRjbtz2tkhtFusSYoKAXkVoVCDifZO9lxqIvWLg+DwdGdW/LD8acybcGnEHzxomRLjHmKOhFpFaUVwZYsGI3z3+8hU15h2nbtBG3fq0n141IpWub5EiXF9MU9CISkvLKALOX7uQPH25h18Gj9OnQnN9cNZhvD+5IUkJ8pMsTFPQiUkOVAecvK3fz2/c2sWN/McO6teZnl/VnTJ/2OvyxnlHQi8hpy9y+n5/+ZS1rdhXSt2MLXpw4nPP7pCjg6ykFvYicsvzCEn759w28nrWLji0b8/T4IVw6qBNxOiyyXlPQi8hJuTtzMnfy87fWU1oe4I4xZ/KDMT1JbqQIaQj0XRKRL7VzfzEPzV/NJ9l7Gdm9DY9fMYju7ZpGuiw5DQp6ETmh17Ny+L9vrMXd+fllA7huRKqmaRogBb2I/IeiknL+35treT1rF+ndWvO7a4boWPgGTEEvIv9mw55CbpuxjB37i7n7gl7cMebMmLr0bzRS0IvIvyxYuZsH5q2iWeMEZmWMZkT3NpEuSWrBSf9Mm9k0M8sPriZ17HP3mZmbWbtqbQ+ZWbaZbTSzb9Z2wSJS+yoDzmNvreOumVn079SCt+78ikI+ipzKiP4l4PfAy9Ubzawr8A1gR7W2fsB4oD9Va8a+b2a9tZygSP11pLSCu2ZmsXBDPjeN7sZPLulHowRN1USTk3433f1jYP9xnvodcD9QfS3CccAsdy91921ANjCiNgoVkdqXe+goV/3xcz7YmM/PLhvAo+MGKOSjUI3m6M3sO8Aud195zCnPnYFF1R7nBNtEpJ7ZuKeICdOWUFRSztSJwxnTp32kS5IwOe2gN7Nk4GHgwuM9fZy2464+bmYZQAZAamrq6ZYhIiFY9sUBbnlpKY0T45j3/XPo27FFpEuSMKrJ/2g9ge7ASjPbDnQBlpvZGVSN4LtW27YLsPt4n8Tdp7h7urunp6Sk1KAMEamJDzfmc8MLi2mdnMi82xTyseC0g97dV7t7e3dPc/c0qsJ9qLvvARYA480sycy6A72AJbVasYjU2N9X5zJ5eibd2zVl7m3n6CSoGHEqh1fOBD4H+phZjplNOtG27r4WmAOsA94GbtcRNyL1w4KVu7ljZhaDu7Zi1q2jSGmeFOmSpI6cdI7e3a89yfNpxzx+DHgstLJEpDa9npXDvXNWkp7WhmkTh9MsSedKxhJ9t0Wi3PzlOdw7dyWje7TlhQnpurRwDNJ3XCSK/WXlbu6bu5JzerZl6oThNE7UGq6xSGdGiESpt9fkcvfsFaSnteFPN6Ur5GOYgl4kCn2wIZ87Z2YxuEtLpk0crumaGKegF4kyi7bu47ZXltHnjOa8dMsI7XgVBb1INFmdc4jJ0zPp0roJL98ykhaNEyNdktQDCnqRKJGdX8RN0xbTskkir0weSZumjSJdktQTCnqRKLD74FFunLqE+Djjlckj6diySaRLknpEk3ciDdzB4rLgVSgrmJUxiu7tmka6JKlnNKIXacCOllUyaXomX+wrZspNwxjQuWWkS5J6SCN6kQaqojLAHa8tZ/mOAzx33VDO6dnu5C+SmKQRvUgD5O48/PoaFm7I59FxA/jWwI6RLknqMQW9SAP0u/c3MztzJ3eMOZMbR3WLdDlSzynoRRqY1xbv4JmFm7lqWBfuvbB3pMuRBkBBL9KAvLcuj5+8sZrz+6Twi8sHcsyazSLHpaAXaSCWfXGAO2cuZ2Dnljx3/VAS4/XrK6fmVFaYmmZm+Wa2plrbk2a2wcxWmdnrZtaq2nMPmVm2mW00s2+Gq3CRWLKl4DCTpy+lQ4vGTNVFyuQ0ncqQ4CXgomPa3gMGuPsgYBPwEICZ9QPGA/2Dr3nOzHRtVJEQ5BeWMGHaEuLMmH7zCNo10xKAcnpOGvTu/jGw/5i2d929IvhwEdAleH8cMMvdS919G5ANjKjFekViSlFJORNeXMr+I2VMmzicNJ31KjVQG5N8twB/D97vDOys9lxOsE1ETlNZRYDbXlnG5rwinrt+KIO7tjr5i0SOI6SgN7OHgQrg1X82HWczP8FrM8ws08wyCwoKQilDJOoEAs59c1fyafY+fnXFIM7v0z7SJUkDVuOgN7MJwLeB6939n2GeA3SttlkXYPfxXu/uU9w93d3TU1JSalqGSNRxdx796zoWrNzN/Rf14YphXU7+IpEvUaOgN7OLgAeA77h7cbWnFgDjzSzJzLoDvYAloZcpEjue+3ALL322nVvO7c73v9Yz0uVIFDjpMVpmNhM4H2hnZjnAI1QdZZMEvBc8YWORu9/m7mvNbA6wjqopndvdvTJcxYtEm5lLdvDkOxu5bEgnfnJJX50QJbXC/nfWJXLS09M9MzMz0mWIRNTfVudyx2vLOa93Cn+6KV0nRMlJmdkyd08/2Xb6SRKpBz7aVMAPZ2VxdmprnfUqtU4/TSIRtnT7fm6dkUmv9s2ZprNeJQwU9CIRtGbXIW55aSmdWjbh5UkjaNkkMdIlSRRS0ItEyPrcQm6YupgWjROZMXmkLm0gYaOgF4mA7PwibnhhMY0T4pn5vVF0btUk0iVJFFPQi9SxrQWHue5Pi4mLM1773khS2yZHuiSJcgp6kTqUnX+Ya6YsojLgvDZ5JD1SmkW6JIkB2r0vUkc25xVx7Z8WAzArYxS9OjSPcEUSKzSiF6kDG/YUMn7KIuJMIS91T0EvEmYrdh7kmucXkRgfx6yMUZzZXtM1Urc0dSMSRp9t2cv3pmfStlkSr04eSdc22vEqdU9BLxIm763L4/bXlpPWNpkZk0bSoUXjSJckMUpTNyJh8NriHdw6I5O+ZzRndsZohbxElEb0IrXI3fnd+5t5ZuFmxvRJ4dnrh+raNRJx+gkUqSVlFQEefn01c5flcHV6F37x3YEk6CqUUg8o6EVqwYEjZdz2yjIWb9vPD8f24u4LemnREKk3TjrcMLNpZpZvZmuqtbUxs/fMbHPwtnW15x4ys2wz22hm3wxX4SL1xdaCw1z+h8/I2nGQp8cP4Z5v9FbIS71yKv9XvgRcdEzbg8BCd+8FLAw+xsz6AeOB/sHXPGdm8bVWrUg988GGfMY9+ymFR8uZmTGScUM6R7okkf9w0qB394+B/cc0jwOmB+9PBy6r1j7L3UvdfRuQDYyopVpF6g1359kPsrll+lK6tk7mjdvPZVi3NpEuS+S4ajpH38HdcwHcPdfM2gfbOwOLqm2XE2wTiRqFJeXcP3cVb6/dw7ghnXj88kE0aaR/XKX+qu2dscebmDzu6uNmlgFkAKSmptZyGSLhsW53IT94dRk7Dxzl4Yv7Mvmr3TUfL/VeTY/9yjOzjgDB2/xgew7Qtdp2XYDdx/sE7j7F3dPdPT0lJaWGZYjUDXdnTuZOvvvcpxSXVTLze6P43nk9FPLSINQ06BcAE4L3JwBvVmsfb2ZJZtYd6AUsCa1EkcgqKinnh7NWcP+8VQzr1pq37voqI7prPl4ajpNO3ZjZTOB8oJ2Z5QCPAI8Dc8xsErADuArA3dea2RxgHVAB3O7ulWGqXSTsVuw8yF0zs9h18Cj3Xdib759/JvFxGsVLw3LSoHf3a0/w1NgTbP8Y8FgoRYlEWkVlgD9+tIWn3t9MhxaNmZ0xivQ0jeKlYdKZsSLH2LGvmHvmrGDZFwe4dHAnfj5uAC2TEyNdlkiNKehFgtyd2Ut38rO/riMuznh6/BCdACVRQUEvAuw5VMKD81fx4cYCRvdoy5NXDaJLay0SItFBQS8xzd15PWsXP12wlrLKAD+9tB83jU4jTjtcJYoo6CVm5RWW8PDrq3l/fT5DU1vx66sG0yNF67lK9FHQS8xxd+Yv38V//WUtpRUBfnJJX24+t7sOm5SopaCXmLL74FF+/PpqPtxYwPC01jxx5WC6t2sa6bJEwkpBLzHB3Zm5ZCe/+Nt6KgOuuXiJKQp6iXo79hXzwJ9X8fnWfZzTsy2PXz6I1LY6okZih4JeolYg4Lz02XaefGcj8XHGLy8fyPjhXXUhMok5CnqJSlsLDnP/vFVkfnGAMX1SeOy7A+nUqkmkyxKJCAW9RJXKgDP1k6385t1NJCXE8ZurBnP50M4axUtMU9BL1NhacJj75q5k+Y6DfKNfBx67bADtWzSOdFkiEaeglwYvEHCmfbqNJ9/ZSOPEeJ66ZgjjhnTSKF4kSEEvDdrO/cXcN3cli7ftZ+xZ7fnl5QM1ihc5hoJeGiR3Z25mDo/+dR0AT1w5iKuGddEoXuQ4Qgp6M7sHmEzVAuCrgZuBZGA2kAZsB6529wMhVSlSzf4jZTw0fxXvrM1jVI82PHnlYLq20XHxIidS0zVjMbPOwF1AursPAOKB8cCDwEJ37wUsDD4WqRUfbSrgm099zAcbCnj44r68NnmUQl7kJEKdukkAmphZOVUj+d3AQ1StMQswHfgQeCDE95EYV1pRyRNvb2TqJ9vo1b4Z028eQb9OLSJdlkiDUOOgd/ddZvZrqhYHPwq86+7vmlkHd88NbpNrZu1rqVaJUVsLDnPXrCzW7CrkxlHdePiSvjROjI90WSINRo2D3sxaA+OA7sBBYK6Z3XAar88AMgBSU1NrWoZEuTeydvHj11fTKCGOKTcO48L+Z0S6JJEGJ5SpmwuAbe5eAGBm84FzgDwz6xgczXcE8o/3YnefAkwBSE9P9xDqkChUUl7JTxesZdbSnYxIa8PT1w6hY0tdwkCkJkIJ+h3AKDNLpmrqZiyQCRwBJgCPB2/fDLVIiS1bCw7zg1eXs2FPEbeP6ck9F/QmIb7Gxw2IxLxQ5ugXm9k8YDlQAWRRNUJvBswxs0lU/TG4qjYKldjw9po9/GjuShLijZduHs75fbSLRyRUIR114+6PAI8c01xK1ehe5JRVVAb49bub+ONHWxjcpSXP3TCMzrrapEit0JmxEnEHjpRx58wsPsney3UjU3nk0n4kJeioGpHaoqCXiFq3u5BbX8kk71ApT1wxiKuHd410SSJRR0EvEfO31bncO2clLZokMPvWUZyd2jrSJYlEJQW91LlAwHnmH5t56v3NDOvWmj/cMJT2zXXFSZFwUdBLnTpaVsl9c1fy1upcrhzWhce+O0Dz8SJhpqCXOpNXWMLk6Zms2X2Ihy/uy+SvdtdlhUXqgIJe6sS63YVMmr6UQ0fL+dON6VzQr0OkSxKJGQp6Cbt/bMjjjteyaNkkkbm3jaZ/p5aRLkkkpijoJaxmLPqCR95cQ79OLZg6YTgdtMyfSJ1T0EtYBALOr97ZwPMfbWXsWe155tqzaZqkHzeRSNBvntS60opK7pu7ir+s3M0No1L56aX9dVEykQhS0EutOnS0nFtnZLJo634e/NZZ3HpeDx1ZIxJhCnqpNbmHjjJx2lK27j3MU9cM4bKzO0e6JBFBQS+1ZHNeEROmLaGwpIIXJ47gK73aRbokEQlS0EvIln2xn1teyqRRQhyzMkYxoLMOnxSpTxT0EpKF6/O4/bXldGzZhJdvGUHXNsmRLklEjhHSoRBm1srM5pnZBjNbb2ajzayNmb1nZpuDt7okYZSak7mTjBnL6N2hOfNuG62QF6mnQj3m7WngbXc/CxgMrAceBBa6ey9gYfCxRBF3548fbeH+eas4p2dbZn5vFG2bJUW6LBE5gRoHvZm1AM4DpgK4e5m7HwTGAdODm00HLgu1SKk/AgHnF39bz+N/38ClgzsxdcJwnQglUs+FMqLvARQAL5pZlpm9YGZNgQ7ungsQvNXqzlGivDLAffNW8qf/2cbEc9J4+pohNErQiVAi9V0ov6UJwFDgD+5+NnCE05imMbMMM8s0s8yCgoIQypC6cLSskltnLGP+8l3c+43ePHJpP+LidCKUSEMQStDnADnuvjj4eB5VwZ9nZh0Bgrf5x3uxu09x93R3T09JSQmhDAm3Q8Xl3Dh1MR9szOex7w7gzrG9dLarSANS46B39z3ATjPrE2waC6wDFgATgm0TgDdDqlAiKq+whKuf/5xVOYd49rqhXD+yW6RLEpHTFOpetDuBV82sEbAVuJmqPx5zzGwSsAO4KsT3kAjZWnCYG6cu4WBxGS/dPJxzztTZriINUUhB7+4rgPTjPDU2lM8rkbc65xATX1wCwKyM0QzsorNdRRoqHRcn/+GTzXu5dUYmrZs24uVbRtAjpVmkSxKRECjo5d8sWLmbe+esoGdKM6bfMkIrQolEAQW9/MuLn27j0b+uY3haG/50UzotmyRGuiQRqQUKesHd+dXbG/njR1u4sF8Hnrn2bBonxke6LBGpJQr6GFdeGeCBP69i/vJdXD8ylUfHDSBeJ0KJRBUFfQw7XFrBD15dzsebCrj3G7254+tn6kQokSikoI9R+YUl3PzSUjbsKeJXVwzkmuGpkS5JRMJEQR+DsvMPM2HaEg4Ul/HChHTG9NF150SimYI+xizauo+Ml/932b9BXVpFuiQRCTMFfQx5I2sXP5q3km5tm/LixOFaEUokRijoY4C789//yOa3721iVI82PH9DOi2TdYy8SKxQ0Ee50opKHvzzal7P2sXlZ3fm8SsGabEQkRijoI9i+w6XcuuMZWR+cYD7LuzN7WN0+KRILFLQR6mNe4qY/PJS8gtLefa6oVwyqGOkSxKRCFHQR6H31uVx96wsmiYlMPvW0QzpqiNrRGKZgj6KuDvPfbiFX7+7kYGdWzLlxnTOaKmrT4rEupCD3szigUxgl7t/28zaALOBNGA7cLW7Hwj1feTLFZdV8KN5q3hrVS6XDu7EE1cMokkjXZhMREJbHPyffgisr/b4QWChu/cCFgYfSxjt3F/M5c99xt9W5/Lgt87imfFDFPIi8i8hBb2ZdQEuAV6o1jwOmB68Px24LJT3kC/30aYCLv39J+w+eJQXJw7ntq/11JE1IvJvQp26eQq4H2hera2Du+cCuHuumelCKmEQCDjPfpDNb9/fRJ8OzfnjDcNIa9c00mWJSD1U46A3s28D+e6+zMzOr8HrM4AMgNRUXTnxdBwqLufeuSt4f30+44Z04peXDyS5kfari8jxhZIO5wLfMbOLgcZACzN7Bcgzs47B0XxHIP94L3b3KcAUgPT0dA+hjpiyOucQP3htGbkHS/jppf2YcE6apmpE5EvVeI7e3R9y9y7ungaMB/7h7jcAC4AJwc0mAG+GXKXg7sxY9AVX/OEzKiudObeNZuK53RXyInJS4fh//3FgjplNAnYAV4XhPWJKUUk5D85fzVurcjm/Twq/u3oIrZs2inRZItJA1ErQu/uHwIfB+/uAsbXxeaVqquaOmcvJOXCU+y/qw23n9SROa7qKyGnQHrx6yt2Z9ul2Hv/7eto1S2J2xijS09pEuiwRaYAU9PXQ3sOl/GjuSj7YWMAFfTvw5JWDNFUjIjWmoK9n/mdzAf9nzkoOHS3nZ+P6c8OobtrhKiIhUdDXE6UVlTz59kZe+GQbvdo3Y8akEZx1RotIlyUiUUBBXw9syivirplZbNhTxE2ju/Hji/vSOFHXqhGR2qGgj6BAwJn++XZ++fcNNE9KYOqEdMb27RDpskQkyijoIySvsIT75q7kfzbv5etntedXVwwipXlSpMsSkSikoI+At1bl8uPXV1NaUcnPLxvA9SNTtcNVRMJGQV+HDh0t56cL1vJ61i4Gd23F764eTI+UZpEuS0SinIK+jnyavZcfzV1JXlEp91zQm9vH9CQhvjbWfRER+XIK+jArKa/kV29v4MVPt9MjpSnzv38Og7VYt4jUIQV9GK3OOcQ9c1aQnX+Yieek8cBFZ2mJPxGpcwr6MKioDPDch1t4ZuFm2jVLYsakEXy1V0qkyxKRGKWgr2Xb9h7hntkrWLHzIOOGdOLR7wygZXJipMsSkRimoK8l7s5rS3bw87+up1FCHP997dlcOrhTpMsSEVHQ14aColIe+PMq/rEhn6/2aseTVw7mjJaNI12WiAgQ2uLgXYGXgTOAADDF3Z82szbAbCAN2A5c7e4HQi+1fnp/XR4P/HkVRaUVPHJpPyaMTtPCICJSr4Qyoq8A7nX35WbWHFhmZu8BE4GF7v64mT0IPAg8EHqp9cvRskp+9tY6Xlu8g74dWzBz/BB6d2ge6bJERP5DjYPe3XOB3OD9IjNbD3QGxgHnBzebTtUSg1EV9Gt3H+KumVlsKThCxnk9uPfC3iQl6LBJEamfamWO3szSgLOBxUCH4B8B3D3XzNrXxnvUB4GAM+3TbTzx9kZaJSfyyqSRfKVXu0iXJSLypUIOejNrBvwZuNvdC0/14lxmlgFkAKSmpoZaRtjtO1zKvXNX8uHGAr7RrwO/umIQbbS8n4g0ACEFvZklUhXyr7r7/GBznpl1DI7mOwL5x3utu08BpgCkp6d7KHWE22fZe7l79goOHi3n0XH9uVHL+4lIA1Ljq2pZVdJNBda7+2+rPbUAmBC8PwF4s+blRVZlwPnte5u4fupimjVO4I0fnMtNo9MU8iLSoIQyoj8XuBFYbWYrgm0/Bh4H5pjZJGAHcFVoJUZGflEJd89awWdb9nHF0C787LL+JDfSaQci0vCEctTNJ8CJhrZja/p564NFW/dx58wsikrKeeLKQVyd3jXSJYmI1JiGqNW4O1M+3soT72ykW9tkXpk0kj5n6Nh4EWnYFPRBRSXl/GjuKt5eu4eLB57BE1cOplmSvjwi0vApyYAtBYfJeDmT7fuK+cklfZn0le7a4SoiUSPmg37h+jzunrWCxIQ4Xpk0ktE920a6JBGRWhWzQe/uPPtBNr95bxP9O7Xg+RvT6dyqSaTLEhGpdTEZ9CXlldw/bxULVu7msiGdePyKQTRO1LVqRCQ6xVzQ5xWWkPFyJqt2HeL+i/rw/a/11Hy8iES1mAr6dbsLmTR9KYeOlvP8DcO4sP8ZkS5JRCTsYiboP9yYz+2vLqd540Tm3jaa/p1aRrokEZE6ERNB/+riL/h/b66lT4fmTJs4XMv8iUhMieqgd3d+8+4mfv9BNmP6pPDf1w3VSVAiEnOiNvXKKwP8eP5q5i7LYfzwrvz8sgEkxNf4Yp0iIg1WVAZ9cVkFt7+6nA82FnD3Bb344dheOrJGRGJW1AX9oeJybpm+lKwdB/jFdwdy3cj6v3qViEg4RVXQ5xeWcNO0JWwtOMKz1w3lWwM7RrokEZGIi5qg37m/mOtfWMzew6VMmzhci3aLiASFbe+kmV1kZhvNLNvMHgzX+wBs23uEq5//nIPFZbwyeaRCXkSkmrAEvZnFA88C3wL6AdeaWb9wvNemvCKufv5zSisCzMwYxdDU1uF4GxGRBitcI/oRQLa7b3X3MmAWMK6232R9biHXPP85BszOGKWzXUVEjiNcQd8Z2FntcU6wrVa1a5bEgM4tmXPraHp10JJ/IiLHE66dscc7aN3/bQOzDCADIDW1ZodApjRPYsakkTV6rYhIrAjXiD4H6FrtcRdgd/UN3H2Ku6e7e3pKSkqYyhARkXBCJdeAAAADyUlEQVQF/VKgl5l1N7NGwHhgQZjeS0REvkRYpm7cvcLM7gDeAeKBae6+NhzvJSIiXy5sJ0y5+9+Av4Xr84uIyKnR5RxFRKKcgl5EJMop6EVEopyCXkQkypm7n3yrcBdhVgB8cRovaQfsDVM59V2s9l39ji3q96np5u4nPRGpXgT96TKzTHdPj3QdkRCrfVe/Y4v6Xbs0dSMiEuUU9CIiUa6hBv2USBcQQbHad/U7tqjftahBztGLiMipa6gjehEROUUNLujrci3aSDKzrmb2gZmtN7O1ZvbDYHsbM3vPzDYHb6Ny7UQzizezLDP7a/Bx1PfbzFqZ2Twz2xD8vo+OkX7fE/wZX2NmM82scbT228ymmVm+ma2p1nbCvprZQ8Gs22hm36zp+zaooK/LtWjrgQrgXnfvC4wCbg/29UFgobv3AhYGH0ejHwLrqz2OhX4/Dbzt7mcBg6nqf1T328w6A3cB6e4+gKqr3Y4nevv9EnDRMW3H7Wvw93080D/4mueCGXjaGlTQU0dr0dYH7p7r7suD94uo+qXvTFV/pwc3mw5cFpkKw8fMugCXAC9Ua47qfptZC+A8YCqAu5e5+0GivN9BCUATM0sAkqlapCgq++3uHwP7j2k+UV/HAbPcvdTdtwHZVGXgaWtoQV8na9HWN2aWBpwNLAY6uHsuVP0xANpHrrKweQq4HwhUa4v2fvcACoAXg1NWL5hZU6K83+6+C/g1sAPIBQ65+7tEeb+PcaK+1lreNbSgP+latNHGzJoBfwbudvfCSNcTbmb2bSDf3ZdFupY6lgAMBf7g7mcDR4ie6YoTCs5HjwO6A52ApmZ2Q2SrqjdqLe8aWtCfdC3aaGJmiVSF/KvuPj/YnGdmHYPPdwTyI1VfmJwLfMfMtlM1Nfd1M3uF6O93DpDj7ouDj+dRFfzR3u8LgG3uXuDu5cB84Byiv9/VnaivtZZ3DS3oY2YtWjMzquZr17v7b6s9tQCYELw/AXizrmsLJ3d/yN27uHsaVd/ff7j7DUR/v/cAO82sT7BpLLCOKO83VVM2o8wsOfgzP5aq/VHR3u/qTtTXBcB4M0sys+5AL2BJjd7B3RvUB3AxsAnYAjwc6XrC2M+vUPVv2ipgRfDjYqAtVXvmNwdv20S61jB+Dc4H/hq8H/X9BoYAmcHv+RtA6xjp938BG4A1wAwgKVr7Dcykal9EOVUj9klf1lfg4WDWbQS+VdP31ZmxIiJRrqFN3YiIyGlS0IuIRDkFvYhIlFPQi4hEOQW9iEiUU9CLiEQ5Bb2ISJRT0IuIRLn/DzZTgmUc+rLRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamos un poco de la función que ha aprendido\n",
    "\n",
    "x = np.arange(1,100)\n",
    "y = model.predict(X_train[x])\n",
    "plt.plot(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
